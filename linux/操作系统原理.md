## 什么是操作系统内核？

内核是计算机上配置的低层软件，是操作系统最基本、最核心的部分

- 提供进程管理、存储器管理、设备管理等功能
- 时钟管理、中断处理、原语（设备驱动、CPU切换） --- 与硬件关联比较紧密的模块

## 进程

程序段、数据段、PCB组成了进程实体（进程映像）

### 进程控制块PCB

进程控制块（Processing Control Block），是操作系统核心中一种数据结构，主要表示**进程状态**。PCB通常是系统内存占用区中的一个连续存区，它存放着操作系统用于**描述进程情况**及**控制进程运行所需的全部信息**，它使一个在多道程序环境下不能独立运行的程序成为一个能独立运行的基本单位或一个能与其他进程并发执行的进程。

### 进程的组织

1. 链接

   通过进程状态将PCB分为多有队列，操作系统持有指向各个队列的指针

2. 索引

   根据进程状态的不同，建立几张索引表，操作系统持有指向各个索引表的指针

### 进程的状态

#### 五状态模型

![](..\imgs\进程状态转换.png)

#### 七状态模型

![](..\imgs\进程七状态模型.png)



### 进程控制

进程控制（状态转换）的过程如果不能“一气呵成”，就有可能导致操作系统中的某些关键数据结构信息不统一的情况， 这会影响操作系统进行别的管理工作。使用原语来保证，原语的执行具有原子性，即执行过程只能一气呵成，期间不允许被中断。 可以用 “关中断指令”和“开中断指令”这两个特权指令实现原子性，如果此时在指令中断间有外部中断，是会忽略掉的

进程的创建，会创建原语

- 申请空白PCB
- 为新进程分配所需资源
- 初始化PCB
- 将PCB插入就绪队列

进程终止，会撤销原语

- 从PCB集合找到终止进程的PCB
- 若正在运行，则剥夺CPU，将CPU分配给其他进程

- 终止所有子进程
- 将进程所拥有的资源归还给父进程或者操作系统
- 删除PCB

进程的阻塞和唤醒，会使用阻塞原语和唤醒原语

进程的切换

### 进程通信

1. 共享内存

   两个进程对共享空间的访问必 须是互斥的，操作系统只负责提供共享空间和同步互斥工具（如P、V操作）

   - 基于数据结构共享

     比如共享空间里只能放 一个长度为10的数组

   - 基于存储区的共享

     在内存中画出一块共享存储区，数据的形式、存放位置都由进程控制

2. 消息传递

   - 直接通信

     进程间的数据交换以格式化的消息（Message）为单位。进程通过操作系统提供的“发送消息/接收 消息”两个原语进行数据交换。消息直接挂到接收进程的消息缓冲队列上，接受进程读取缓存队列

   - 间接通信

     消息要先发送到中间实体（信箱）中，因此 也称“信箱通信方式”

3. 管道通信

   - 管道只能采用半双工通信，某一时间段内只能实现单向的传输。如果要实现双向同时通信，则需要设置两个管道
   - 各进程要互斥地访问管道。 
   -  数据以字符流的形式写入管道，当管道写满时，写进程的write()系统调用将被阻塞，等待读进程将数据 取走。当读进程将数据全部取走后，管道变空，此时读进程的read()系统调用将被阻塞。 
   - 如果没写满，就不允许读。如果没读空，就不允许写。 
   - 数据一旦被读出，就从管道中被抛弃，这就意味着读进程最多只能有一个，否则可能会有读错数据的情 况

### 三层调度

|                       | 要做什么                                                     | 调度发生在..            | 发生频率 | 对进程状态的影响                    |
| --------------------- | ------------------------------------------------------------ | ----------------------- | -------- | ----------------------------------- |
| 高级调度 （作业调度） | 按照某种规则，从后备队列 中选择合适的作业将其调入内存，并为其创建进程 | 外存->内存（面向作业）  | 最低     | 无->创建态->就绪态                  |
| 中级调度 （内存调度） | 按照某种规则，从挂起队列中选择合适的进程将其数据调回内存     | 外存->内存 （面向进程） | 中等     | 挂起态->就绪态 （阻塞挂起->阻塞态） |
| 低级调度 （进程调度） | 按照某种规则，从就绪队列中选择一个进程为其分配处理机         | 内存->CPU               | 最高     | 就绪态->运行态                      |

### 为什么需要进程调度？

因为每个进程对计算机资源的需求是不同的

第一种分类：

- 有I/O密集型的，在等待I/O的时间就可以让CPU执行其他进程的任务
- 有CPU密集型的，如果这种进程大量占用CPU，其他交互式进程就会带来卡顿

第二种分类：

- 批处理进程（batch process）

  后台运行，不必很快响应

- 实时进程（real-time process）

  不应被低优先级的进程阻塞，相应时间要短，稳定

- 交互式进程（interactive process）

  需要消耗时间等待用户输入，相应时间要快

### 进程调度的时机

#### 主动放弃

1. 进程正常终止
2. 运行过程中发生异常而终止
3. 进程主动请求阻塞（如 等待I/O）

#### 被动放弃

1. 分给进程的时间片用完
2. 有更紧急的事需要处理（如 I/O中断）
3. 有更高优先级的进程进入就绪队列

#### 不能进行进程调度

1. 在处理中断的过程中。中断处理过程复杂，与硬件密切相关，很难 做到在中断处理过程中进行进程切换。

2. 进程在操作系统内核程序临界区中。

   临界资源：一个时间段内只允许一个进程使用的资源。各进程需要互斥地访问临界资源。内核程序临界区一般是用来访问某种内核数据结构的，比如进程的就绪队列

3. 在原子操作过程中（原语）

### 进程调度算法

由于资源有限，无法全部同时处理任务，需要根据某种**规则**，决定**什么时候以怎么样的方式**选择一个进程运行

根据系统的资源分配策略所规定的资源分配算法

#### 非抢占方式

又称非剥夺式。即，只允许进程主动放弃处理机。在运行过程中即便有更紧迫 的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动要求进入阻塞态。**适合于早期的批处理系统**

- 先来先服务（FCFS，First Come First Serve）

  先进先出或严格排队方案。当每个进程就绪后，它加入就绪队列。当前正运行的进程停止执行，选择在就绪队列中存在时间最长的进程运行。

- 最短工作优先（SJF，Shortest Job First）

  短作业优先调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。当作用于进程时，也称为SPF，Shortest Process First

- 最高响应比优先（HRRF，Highest Response Ratio Next）

  综合考虑作业/进程的等待时间和要求服务的时间，在调度是选择响应比最高的作业/进程为其服务

#### 抢占式

又称抢占方式。当一个进程正在处理机上执行时，如果有一个更重要或更紧迫的进 程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给更重要紧迫的那个进程。**适合于分时操作系统、实时操作系统**

- 最短剩余时间优先（SRTF，Shortest Remaining Time Next）

  每当有进程加入就绪队列改变时就需 要调度，如果新到达的进程剩余时间比当前运行的进程剩余时间更短，则由新进程抢占处理机

- 时间片轮转调度（PR，Pround-Robin）

  系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中第一个进程执行，即先来先服务的原则，但仅能运行一个时间片（如100ms，由时钟装置发出时钟中断控制）。在使用完一个时间片后，即使进程并未完成其运行，它也必须释放出（被剥夺）处理机给下一个就绪的进程，而被剥夺的进程返回到就绪队列的末尾重新排队，等候再次运行

- 优先级调度（Priority）

  每个作业/进程有各自的优先级，调度时选择优先级最高的作业

  静态优先级：创建进程时确定，之后一直不变

  动态优先级：创建进程时有一个初始值，之后会动态调整优先级

  通常：

  - 系统进程 优先级高于 用户进程
  - 前台进程 优先级高于 后台进程
  - I/O型进程 优先级高于 计算型进程

- 多级反馈队列调度算法

  对其他调度算法的折中权衡，设置多级就绪队列，各队列优先级从高到低，时间片从小到大，每个队列内按FCFS原则排队等待

### 进程互斥

#### 软件实现

1. 单标记法

   两个进程在访问完临界区后会把使用临界区的权限转交给另一个进程，违背“空闲让进”

2. 双标志先检查法

   设置一个布尔数组flag[]，数组中各个元素标记各进程想进入临界区的意愿，违反“忙则等待”，可能会同时访问临界区，原因在于“检测”和“上锁”不是原子性操作

3. 双标志后检查法

   算法2是先“检查”后“上锁”，而此方法先“上锁”后“检查”，可能发生都无法进入临界区

4. Peterson算法

   在双标志后检查法中，若两个进程出现竞争，可以让线程尝试让出。违反“让权等待”

#### 硬件实现

1. 中断屏蔽

   使用开关中断指令 ，防止发生进程切换，不适用于多处理机

2. TestAndSet指令

   简称TS指令，也称TestAndSetLock指令（TSL），**使用硬件实现**，执行的过程不允许被中断，适用于多处理机环境

3. Swap指令

   也称Exchange指令（XCHG），使用硬件实现，交换两个变量的值

#### 信号量

用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作，从而很方便的实现了**进程互斥**（设置初始值为1）、**进程同步**（设置初始值为0）。

信号量其实就是一个变量（可以使用结构体，带一个队列），可以用一个信号量 来表示系统中某种资源的数量

**一对原语：wait(S) 原语和 signal(S) 原语，常简称为 P、V操作（来自荷兰语 proberen 和 verhogen）**

## 死锁

### 预防死锁

1. 互斥条件：如果把只能互斥使用的资源改造为允许共享使用，则系统不会进入死锁状态。比如: SPOOLing技术（引入一个中间进程）
2. 不剥夺条件：主动释放 或者 剥夺其他进程资源
3. 请求和保持条件：采用静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前， 不让它投入运行。
4. 循环等待条件：可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源， 同类资源（即编号相同的资源）一次申请完

### 避免死锁 --- 银行家算法

安全序列：指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是安全状态。当然，安全序列可能有多个，如果系统处于安全状态，就一定不会发生死锁。.

==“银行家算法”核心思想：在资源分配之前预先判断这次分配是否会导致系统进入不安全状态==，如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待

假设系统中有 n 个进程，m 种资源 每个进程在运行前先声明对各种资源的最大需求数

则可用一个 n*m 的矩阵Max，表示所有进程对各种资源的最大需求数，Max[i, j]=K 表示进程 Pi 最多需要 K 个资源 Rj。分配矩阵 Allocation 表示对所有进程的资源分配情况， Need 矩阵 = Max – Allocation ，表示各进程最多还需要多少各类资源，长度为m的一维数组 Available 表示 当前系统中还有多少可用资源

银行家算法步骤：

①检查此次申请是否超过了之前声明的最大需求数

②检查此时系统剩余的可用资源是否还能满足这次请求

③试探着分配，更改各数据结构

④用安全性算法检查此次分配是否会导致系统进入不安全状态

安全性算法步骤： 

检查当前的剩余可用资源是否能满足某个进程的最大需求，如果可以，就把该进程加入安全序列， 并把该进程持有的资源全部回收。 

不断重复上述过程，看最终是否能让所有进程都加入安全序列

### 死锁的检测

依次消除与不阻塞进程相连的边，直到无边可削

①在资源分配图中，**找出既不阻塞又不是孤点的进程 Pi**（即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有空闲资源数量。（若所有的连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源），**消去它所有的请求边和分配变，使之称为孤立的结点**。在

②进程 Pi 所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。进行一系列化简后，==若能消去途中所有的边，则称该图是可完全简化的==（如果某时刻系统的资源分配图 是不可完全简化的，那么此时系统死锁）

### 死锁解除

用死锁检测算法化简资源分配图后，还连着边的那些进程就是死锁进程

1. 资源剥夺法

   挂起（暂时放到外存上）某些死锁进程，并抢占它的资源，将这些资源分配给 其他的死锁进程

2. 撤销进程法

   强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源

3. 进程回退法

   让一个或多个死锁进程回退到足以避免死锁的地步。这就要求系统要记录进程的历史信息，设置还原点

## 管程 

管程，Monitor是一种特殊的软件模块，用来实现进程互斥、同步，**指的是管理共享变量以及对其操作过程，让它们支持并发访问**

1. 局部于管程的共享数据结构说明
2. 对该数据结构进行操作的一组过程
3. 对局部于管程的共享数据设置初始值的语句
4. 管程有一个名字

==由编译器负责实现 各进程互斥地进入管程中的过程，只会有一个进程访问缓冲区==

### 为什么要引入管程？

信号量机制存在问题：编写程序困难、易出错

管程利用OOP的封装特性解决了信号量在工程实践上的复杂性问题

## 线程

### 为什么要引入线程？

一个进程内，需要完整不同的功能，在以进程为调用单位是没有办法完成的。

当切换进程时，需要保存/恢复进程运行环境， 还需要切换内存地址空间（更新快表、更新缓 存）开销很大，在引入线程之后，==进程依然是资源分配的基本单位。==从属于同一进程 的各个线程共享进程的资源，==线程是 CPU调度的基本单位==

同一进程内的各个 线程间并发，不需要切换进程运行环境和内存地址空间，带来并发性的提升

引入线程前，进程既是资源分配的基本单位，也是调度的基本单位。 引入线程后，进程是资源分配的基本单位，线程是调度的基本单位。

### 线程的属性

线程是CPU调度的单位

每个线程都有一个线程ID、线程控制块（TCB）

多CPU计算机中，各个线程可占用不同的CPU

同一个进程中的不同线程共享进程的资源

### 线程的实现方式

**用户级线程（User-Level Thread，ULT）**

用户级线程由应用程序通过线程库实现。 所有的线程管理工作都由应用程序负责（包括线程切换） 用户级线程中，线程切换可以在用户态下即可完成，无需操作系统干预。

**内核级线程（Kernel-Level Thread, KLT）**

内核级线程的管理工作由操作系统内核完成。 线程调度、切换等工作都由内核负责，因此 内核级线程的切换必然需要在核心态下才能 完成。

**多对多模式，将n个用户级线程映射到m个内核级线程上**

操作系统只“看得见”内核级线 程，因此只有内核级线程才是CPU分配的单位

## 中断和异常

当中断发送时，CPU立即进入核心态，当前运行的进程暂停执行，并由操作系统内核对中断进行处理，对于不同的中断信号，会进行不同的处理

- 内中断（异常）
  - 主动中断，指令中断
  - 被迫中断，硬件故障（缺页），软件中断（除0）
- 外中断，外设请求，人工干预

## 内存

内存可存放数据。程序执行前需要先放到内存中才能被CPU处理——缓和CPU与硬盘之间的速度矛盾

### 连接

由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块 装入（装载）：由装入程序将装入模块装入内存运行

1. 静态链接

   在程序运行之前， 先将各目标模块及它们所需的库函数连接成一个完整的可执行文件（装入模块）， 之后不再拆开。

2. 装入时动态链接

   将各目标 模块装入内存时，边装入边链接的链接方式

3. 运行时动态链接

   在程序执 行中需要该目标模块时，才对它进行链接。其优点是便 于修改和更新，便于实现对 目标模块的共享

### 装入

C语言程序经过编译、 链接处理后，生成装入模块，即可执行文件

1. 绝对装入

   在编译时，如果知道程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码。只适用于单道程序环境

2. 静态重定位

   又称可重定位装入，编译、链接后的装入模块的地址都是从0开始的，指令中使用的地 址、数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置

   特点：必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。

    作业一旦进入内存后，在运行期间就不能再移动，也不能再申请内存空间。

3. 动态重定位

   又称动态运行时装入，装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把地址转换推迟到程序真正要执行时才进行。需要一个重定位寄存器的支持

### 内存管理

1. 内存空间的分配与回收

   - 连续分配

     - 单一连续分配

     - 固定分区分配

     - 动态分区分配

       - 首次适应法

         从头到尾找适合的 分区

       - 最佳适应算法

         优先使用更小的分区，以保留更多大分区

       - 最坏适应算法

         优先使用更大的分区，以防止产生太小的不可用的碎片

       - 邻近适应算法

         由首次适应演变而 来，每次从上次查找结束位置开始查找（循环链表）

   - 非连续分配

     - 基本分页存储管理

       将内存空间分为一个个大小相等的分区，每个分区就是一个“页框”

     - 基本分段存储管理

       分段系统的逻辑地址结构由段号（段名）和段内地址（段内偏移量）所组成，大小不相等

     - 段页式存储管理

   内部碎片：分配给某进程的内存区域中，如果有些部分没有用上

   外部碎片：内存中的某些空闲分区由于太小而难以利用

2. 内存空间扩充

   - 覆盖技术，将程序分为多个段（多个模块）。 常用的段常驻内存，不常用的段在需要时调入内存

     需要常驻内存的段放在“固定区”中，调入后就不再调出，不常用的段放在“覆盖区”，需要用到时调入内存， 用不到时调出内存

     需要用户指定，增加了用户编程负担

   - 交换技术，内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存

   - 虚拟内存技术

3. 地址转换

   负责程序的逻辑地址与物理地址的转换

4. 内存保护

   保证各进程在各自存储空间内运行，互不干扰

   - 设置一对上、下限寄存器，检查是否越界
   - 采用重定位寄存器和界地址寄存器进行越界检查，重定位寄存器中存放的是进程的起始物理地址。界地址寄存器中存放的是进程的最大逻辑地址。

#### 分页和分段的对比

页是信息的物理单位。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的。

段是信息的逻辑单位。分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻 辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名。

页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序。

|          | 优点                                                     | 缺点                                                         |
| -------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| 分页管理 | 内存空间利用率高，不会产生外部碎片，只会有少量的页内碎片 | 不方便实现信息的共享和保护                                   |
| 分段管理 | 更容易实现信息的共享和保护                               | 会产生外部碎片，若果段长多大，为其分配很大的连续空间会很不方便 |

#### 段页式存储管理

==先将进程按逻辑模块分段，再将各段分页==，段页式系统的逻辑地址结构由段号、页号、页内地址组成

## 局部性原理

时间局部性：如果执行了程序中某条指令，那么不久后这条指令很有可能会再次执行，如果某个数据被访问过，不久之后该数据很可能再次被访问（程序中存在大量的循环）

空间局部性：一旦程序访问了某个储存单元，在不久之后，其附近的存储单元也很有可能背访问（数据在内存中的一个块内是连续的）

## 为什么要有用户态和内核态？

1. 为了保护操作系统，不让一般操作直接访问内核

2. 保证公平，假如没有内核态，所有操作系统内部的功能都交给用户自己使用，如果每个进程都能够修改时钟，那么进程就都可以保证自己的CPU时间片是无限长的，资源竞争产生了不公平

   内核态可以执行特权指令，而用户态只能执行非特权指令

   使用程序状态字寄存器（PSW）中的某位标志位l来标识的，0属于用户态，1属于内核态

用户态 -> 核心态：中断

核心态 -> 用户态：执行一个特权指令，将PSW标志位设置为用户态

## 为什么需要虚拟内存？

传统存储管理的缺点：

1. 一次性，作业必须一次性全部装入内存中后才能开始运行
   - 作业很大时不能装入，无法运行
   - 多个作业要运行时，无法容纳，并发度低
2. 驻留性，作业一旦装入，就会一直装入在内存中（根据局部行原理，只有一小部分会运行）

基于局部性原理，在程序装入时，可以将程序中很快 会用到的部分装入内存，暂时用不到的部分留在外存

若没有虚拟内存机制，程序指令所访问的内存地址就是物理内存地址。当计算机同时运行多个程序时，必须保证这些程序用到的内存总量要小于计算机实际物理内存的大小。这样有几个问题，

1. 进程空间不隔离，一个进程会影响另一个进程的数据，甚至恶意程序可以修改别的进程的内存数据
2. 内存利用率低，若系统剩余内存不足，需要将进程的数据暂时拷贝到硬盘中，释放部分空间给新的进程使用
3. 程序运行的地址不确定，新分配的进程它的地址是随机连续的

为了解决上述问题，引入一个虚拟内存的中间层，利用间接的地址访问去访问物理内存，程序访问虚拟地址，由操作系统将其映射到合适的物理内存上。

**分段(Sagmentation)**：

可以解决1，3问题，因为在虚拟地址空间和物理地址空间之间做一一映射，无法解决2问题

**分页（Paging）**：

程序的运行有局部性特点，在某个时间段内，程序只是访问程序的一小部分数据，采用粒度更小的内存分割和映射方法解决效率问题。

分页的基本方法是，将地址空间分成许多的页（一般为4KB），其思想是程序运行时用到哪页就为哪页分配内存，没用到的页就暂时保存在硬盘上，用到了就加载进物理内存，建立虚拟空间到物理空间的映射。

页表结构：

| 内存块号         | 状态位置         | 访问字段             | 修改位                       | 外存地址               |
| ---------------- | ---------------- | -------------------- | ---------------------------- | ---------------------- |
| 实际物理内存位置 | 页面是否在内存中 | 记录最近被访问了几次 | 修改过的页面在置换时写会外存 | 页面在外存中存放的地址 |



### 如何实现地址的转换？

32位二进制，页面大小为4KB（2的整数幂）

1. 计算所处逻辑地址对应的页号（低12位全是0~1，高位仅有一个为1，可以快速计算）
2. 操作系统使用 **页表** 数据结构存储了页面在内存中的起始地址（块号 * 页面大小），进程被调度时，把它放入 **页表寄存器** （PTR）
3. 算出逻辑地址在页面内的偏移量（低12位就是偏移量）
4. 物理地址=页面起始地址 +  页内偏移量

### 什么是快表？

快表，又称联想寄存器（TLB），是一种访问速度比内存快很多的==高速缓存储器==，用来存放当前访问的若干页表项，以加速地址表换的过程。与此对应，内存中的页表常称为慢表

### 什么是两级页表？

1. 页表必须连续存放，需要占用很多个连续的页框
2. 没有必要让整个页表常驻内存（页表项增加一个标志位，是否在内存中）

假设32为逻辑地址，页面大小为4KB，则进程最多有2^20个页面，这个数字太大了，要遍历查找的话太慢了，因此多建立一级页表目录（相当于索引），一级页号设为4B，每个一级页表可以存储1024个页面（把他们装入内存中，先访问内存块号，找到二级页表）

**可执行文件的运行过程：**

一个可执行文件(Widows，PE文件，Linux，ELF文件)其实就是一些编译链接好的数据和指令的集合，它也会被分成很多页，当一个可执行文件夹被执行时，操作系统首先创建一个4GB的进程虚拟地址空间，它只是创建了页目和页表这种数据结构，来实现映射机制。

首先读取可执行文件的第一页，将文件头和段表信息映射到页中，但是真正的指令和数据没有装入内存，当CPU访问应用程序中的某个虚拟地址时，CPU发现没有相关联的物理地址，则认为页错误（Page Fault），然后分配内存，进程从刚才发生页错误的位置重新开始执行。随着程序的执行，页错误会不断地产生，操作系统也会为进程分配相应的物理页面来满足进程执行的需求



## 页置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。

当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法

页面的换入换出时需要磁盘I/O，会有比较大的开销，因此需要尽量减少换页次数（缺页率）

1. **最佳置换算法（OPT）**

   每次选择淘汰的页面将是以后**永远不使用的页面**，或者是在**最长时间不再被访问的页面**

   无法实现，当缺页发生时，==只有在执行进程时才知道接下来访问的是哪个页面==，操作系统无法知道各个页面下一次是在什么时候被访问。虽然这个算法不可能实现，但是最佳页面置换算法可以用于对可实现算法的性能进行衡量比较

2. **先进先出置换算法（FIFO）**

   当需要淘汰一个页面时，总是选择驻留主存时间最长的页面进行淘汰，即先进入主存的页面先淘汰。其理由是：最早调入主存的页面不再被使用的可能性最大

   实现：**使用队列**，换出时选择队头即可

   Belady异常：为进程分配的物理块数增大时，缺页次数不减反增的现象

3. **最近最久未使用（LRU）算法**

   利用局部性原理，根据一个作业在执行过程中过去的页面访问历史来推测未来的行为，当需要淘汰一个页面时，总是选择在最近一段时间内最久不用的页面予以淘汰

   实现：利用页面中的  ==访问字段==

4. **时钟(CLOCK)置换算法，NRU**

   称为最近未用(Not Recently Used, NRU)算法，它是LRU的近似实现

   由于LRU算法的性能接近于OPT，但是实现起来比较困难，且开销大；FIFO算法实现简单，但性能差。

   将访问字段改为访问标志，1代表最近访问过，0代表最近没有访问

   实现：==设置访问位，将内存中的页面通过指针连接成**循环队列**==，当页面访问时，检查如果为0，则换出，如果为1则置0，继续检查下一个页面（最多会进行两轮扫描）

   PS：循环链表围成一个圆圈，指针在里面转动很像时钟

5. **改进型时钟置换算法**

   简单时钟置换算法仅仅考虑到一个页面最近是否被访问过，只有在页面被修改过，才需要写会外存（读操作就不需要），可减少I/O次数

   ==在其他条件都相同时，应优先淘汰没有没有被修改过的页面==，使用（修改位，访问位）表示

   实现和简单时钟置换算法一样，使用 循环队列，找到第一个（0，0）进行替换，最多会进行四轮扫描（所有都为（1，1））

   - 第一轮找（0，0）
   - 第二轮找（0，1）
   - 第三轮找（0，0）
   - 第四轮找（0，1）

6. **最少使用（LFU）置换算法**

   为在内存中的每个页面设置一个移位寄存器，用来记录该页面被访问的频率，选择在之前时期使用最少的页面作为淘汰页

### 页缺失

当软件试图访问已映射在虚拟地址空间中，但是并未被加载在物理内存中的一个分页时，由中央处理器的内存管理单元所发出的中断



## 文件管理

![](..\imgs\文件系统的层次结构.png)

### 文件的逻辑结构

- 无结构文件

  文件内部的数据就是一系列二进制流或字符流组成，又称“流式文件”，如.txt 文件

- 有结构文件

  由一组相似的记录组成，又称“记录式文件”。每条记录又若干个数据项组成，根据各条记录的长度（占用的 存储空间）是否相等，又可分为定长记录和可变长记录两种

  

### 文件控制块

FCB 的有序集合称为“文件目录”，一个FCB就是一个文件目录项。 

==FCB 中包含了文件的基本信息（文件名、物理地址、逻辑结构、物理结构等）==，存取控制信息（是否可读/可写、禁止访问的用户名 单等），使用信息（如文件的建立时间、修改时间等）。

### 索引结点

对FCB的改进，除了文件名 之外的文件描述信息都之后的信息 都放入到索引结点中

若使用索引结点机制，文件名占14B，索引结点指针站2B

### 文件分配的方式（物理结构）

1. 连续分配

   连续分配方式要求每个文件在磁盘上占有一组连续的块，支持顺序访问 和直接访问（即随机访问）。

   优点：支持顺序访问和直接访问（即随机访问，需要来回移动磁头）；连续分配的文件在顺序访问时速度最快 

   缺点：不方便文件拓展；存储空间利用率低，会产生磁盘碎片

2. 链接分配

   - 隐式链接

     目录项FCB中记录了文件 存放的起始块号和 结束块号，通过链表的方式挨个寻找

     优点：很方便文件拓展，不会有碎片问题，外存利用率高。 

     缺点：只支持顺序访问，不支持随机访问，查找效率低，指向下一个盘块的指针也需要耗费少量 的存储空间

   - 显式连接

     录项FCB中只需记录 文件的起始块号，把用于链接文件各物理块的指针显式地存放在一张表中，即**文件分配表（FAT，File Allocation Table）**

     一个磁盘仅设置一张FAT。 开机时，将FAT读入内存，并常驻内存

3. 索引分配

   索引表存放的磁盘块称为索引块，文件数据存放的磁盘块称为数据块，一个文件对应一张

   索引分配方式可以支持随机访问。 文件拓展也很容易实现（只需要给文件分配 一个空闲块，并增加一个索引表项即可） 但是索引表需要占用一定的存储空间

   1. 链接方案

      如果索引表太大，一个索引块装不下，那么可以将多个索引块链接起来存放

   2. 多层索引

      使第一层索引块指向第二层的索引块。还可根据 文件大小的要求再建立第三层、第四层索引块

   3. 混合索引

      多种索引分配方式的结合，一个文件的顶级索引表中，既包含直接地址索引（直接 指向数据块），又包含一级间接索引，还包含两级间接索引

### 存储空间管理

成组链接法

### 打开文件

1. 将目录项的信息复制到内存中的打开文件表中，并将打开文件表的索引号返回给用户
2. 打开文件之后，对文件的操作可以根据内存中的打开文件表进行操作
3. 每个进程有自己的打开文件表，系统中也有一张总的打开文件表
4. 进程打开文件表特有属性：读写指针、访问权限
5. 系统打开文件表：打开计数器（多少个进程打开了文件）

### 文件共享

#### 基于索引结点的共享方式（硬连接）

索引结点，是一种文件目录瘦身策略。由于检索文件时只需用到文件名，因此可以将除了文件名之外的其他信息放到索引结点中。这样目录项就只需要包含文件名、索引结点指针。

==索引结点中设置一个链接计数器count，表示链接到本索引结点上的用户目录项数量==

删除时，count减1，当count=0时，系统负责删除文件

### 基于符号链的共享方式（软连接）

创建了一个Link类型的文件，记录了文件的存放路径，==并且创建了新的索引结点==

当记录的文件不存在时，链接就失效了



## 磁盘

![](..\imgs\磁盘结构.png)

![](..\imgs\磁盘的物理地址.png)

### 磁盘调度算法

1. 先来先服务（FCFS）

   根据进程请求访问磁盘的先后顺序进行调度

2. 最短寻找时间优先（SSTF）

   优先处理的磁道是当前磁头最近的磁道，每次寻道时间最短，总体并不一定最短（贪心），会产生饥饿现象

3. 扫描算法（电梯算法、SCAN）

   只有磁头移动到最外侧磁道的时候才能往内移动，移动到最内侧磁道的时候才能往外移
   动。这就是扫描算法(SCAN) 的思想。由于磁头移动的方式很像电梯，因此也叫电梯算法。

4. 循环扫描算法（C-SCAN）

   SCAN算法对于各个位置磁道的响应频率不平均，而C-SCAN算法就是为了解决这个问题。规定只有磁头朝某个特定方向移动时才处理磁道访问请求，而返回时直接快速移动至起始端而不处理任何请求。

5. LOOK算法

   扫描算法(SCAN) 中，只有到达最边上的磁道时才能改变磁头移动方向，事实上，处理了最右边磁道的访问请求之后就不需要再往右移动磁头了。LOOK调度算法就是为了解决这个问题，如果在磁头移动方向上已经没有别的请求，就可以立即改变磁头移动方向。(边移动边观察， 因此叫LOOK)

6. C-LOOK算法

   C-SCAN算法的主要缺点是只有到达最边上的磁道时才能改变磁头移动方向，并且磁头返回时不一定需要返回到最边缘的磁道上。C-LOOK 算法就是为了解决这个问题。如果磁头移动的方向上已经没有磁道访问请求了，就可以立即让磁头返回，并且磁头只需要返回到有磁道访问请求的位置即可。



