## OSI模型 ##
开放系统互联 Open System Interconnection
![](https://img-blog.csdn.net/20180316155619885?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3FxXzE2MDkzMzIz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

1. 物理层

   负责0、1比特流与电压的高低、灯光的闪灭之间的转换

   设备：网卡、集线器、中继器

   协议：IEEE802.3

2. 数据链路层

   将0、1序列划分为具有意义的数据帧，为网络层提供**差错控制**和**流量控制**服务

   设备：网桥、交换机

   协议：ARP、RARP、PPP

3. 网络层

   通过路由选择算法为数据包选择最佳路径，从而实现**阻塞控制**、**网络互联**等功能

   设备：路由器

   协议：IP、ICMP、IGMP

4. 传输层

   起可靠传输的作用。是网络体系结构中高低层之间衔接的接口，主要处理**数据报错误、数据包次序**等传输问题

   协议：TCP、UDP

5. 会话层

   管理通信。负责建立和断开连接的时机，采用何种连接方式，以及数据的分割等信息传输相关的管理。

6. 表示层

   将应用处理的信息转换为合适网络传输的格式，或者将合适网络传输的格式转换为应用处理的信息（上下层互换）

7. 应用层

   为应用程序提供服务并规定应用程序中通信相关的细节。

   协议：HTTP、SMTP（邮件传送）、FTP、POP（接收邮件）、Telnet（远程登录）、DNS

原始比特流的传输电子信号传输和硬件接口数据发送时，从第七层传到第一层，接受方则相反。

1. 数据链路层—在此层将数据分帧，并处理流控制。本层指定拓扑结构并提供硬件寻址

2. 网络层—本层通过寻址来建立两个节点之间的连接，它包括通过互连网络来路由和中继数据

3. 传输层—常规数据递送－面向连接或无连接。包括全双工或半双工、流控制和错误恢复服务 

4. 会话层—在两个节点之间建立端连接。此服务包括建立连接是以全双工还是以半双工的方式进行设置，尽管可以在层4中处理双工方式

5. 表示层—格式化数据，以便为应用程序提供通用接口。这可以包括加密服务

6. 应用层

7. —直接对应用程序提供服务，

### MTU（Maxitum Transmission Unit）

 最大传输单元，是由物理层产生的限制，通常与通信接口有关

### MSS（Maxitum Segment Size）

最大分段大小，即TCP数据包每次能够传输的最大数据分段。为了达到最佳的传输效能，TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往用MTU值代替

## TCP/IP四层模型

![](..\imgs\OSI_TCP.jpg)

## TCP为什么可靠？

1. 序列号与确认号

   当发生错误时：

   - 超时重传机制

     发送方发送的报文中含有序列号，每当发送一个报文后，就启动一个计时器（RTO）

   - 快速重传机制

     当接收方发送接受的序列号不对的时候，发送连续的3个ACK标志，告诉发送方，这个报文在传输过程中出现了丢包。发送方如果接收到某个相同序列号的三个ACK报文，那么此时立马重发该报文，不用等待计时器的时间结束。

2. 流量控制
3. 阻塞控制

## TCP三次握手 ##

1. 刚开始客户端处于 closed 的状态，服务端处于 listen 状态。
1. 第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 Seq，此时客户端处于 SYN_Send 状态。
2. 第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 Seq，同时会把客户端的 Seq + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD 的状态。
3. 第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的Seq + 1作为ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised 状态。
4. 服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。

注：
SYN - Synchronize同步
Seq - Sequence序列
ACK - Acknowledgment答复
### 为什么要三次握手？ ###

1. 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
2. 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时**服务器并不能确认客户端的接收能力是否正常**。
3. 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。

### 三次握手的作用 ###
1. 确认双方的接受能力、发送能力是否正常。
2. 指定自己的初始化序列号，为后面的可靠传送做准备。
3. 如果是 https 协议的话，三次握手这个过程，还会进行数字证书的验证以及加密密钥的生成到。

### TCP-SYN Flood攻击

TCP-SYN Flood攻击又称**半开式连接攻击**，每当我们进行一次标准的TCP连接，都会有一个三次握手的过程，而TCP-SYN Flood在它的实现过程中**只有前两个步骤**。这样，服务方会在一定时间处于等待接收请求方ACK消息的状态。由于一台服务器可用的TCP连接是有限的，如果恶意攻击方快速连续地发送此类连接请求，则服务器可用TCP连接队列很快将会阻塞，系统资源和可用带宽急剧下降，无法提供正常的网络服务，从而造成拒绝服务。

### 半连接队列和全连接队列

(1)client端使用connect()向server端发起连接请求(发送syn包)，此时client端的TCP的状态为**SYN_SENT**

(2)server端在收到SYN包后，将TCP相关信息放到syn queue(半连接队列)中，同时向client发送syn+ack。server端TCP的状态为**SYN_RCVD**。

(3)client端收到server端的syn+ack后，向server端发送ack，此时client端的TCP的状态为**ESTABLISHED**。Server端收到ack确认后，从**syn queue**里将TCP信息取出，并放到**accept quee**(全连接队列)中，此时server端的TCP的状态为**ESTABLISHED**。

#### 半连接队列(SYN queue)

当 SYN queue满了，系统还在不断的收到 SYN 包时，统会根据内核参数**net.ipv4.tcp_syncookies**的值来处理请求，tcp_syncookies是用来防止**SYN flood攻击**，其原理是在半连接队列满时，SYN cookies并不丢弃SYN请求，而是将源目的IP、源目的端口号、接收到的client端初始序列号以及其他一些安全数值等信息进行hash运算，并加密后得到server端的初始序列号，称为cookie。

server端在发送初始序列号为cookie的SYN+ACK包后，会将分配的连接请求块释放。如果接收到client端的ACK包，server端将client端的ACK序列号减1得到的值，与上述要素hash运算得到的值比较，如果相等，直接完成三次握手，构建新的连接。

## TCP四次挥手 ##

1. 刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求
2. 第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态
3. 第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT状态
4. 第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态
5. 第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态
6. 服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态

注：
FIN - Finish结束

### 为什么要四次挥手？ ###
因为TCP是全双工，客户端与服务器端都可以发送和接收数据，关闭一方发送和一方接收需要两次挥手，一共就为四次了

### TIME_WAIT

客户端收到服务的释放连接的请求后，不是立马进入CLOSE状态，而是还要再等待2MSL(Maximum Segment Lifetime)。

- 确保最后一个确认报文能够到达。

  - 如果没能到达，服务端就会重发FIN请求释放连接
  - 如果服务器端收到客户端的ACK，不会再发送任何消息，直接进入CLOSED状态。

  无论以上哪种情况，客户端都需要等待，取这两种等待情况时间的最大值，即2MSL，**以应对最坏的情况发生**

- 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文

### TIME_WAIT过多的危害，如何避免

在**高并发短连接**的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接

- 过多的话会占用内存，一个TIME_WAIT占用4k大小
- 高并发可以让服务器在短时间范围内同时占用大量端口

避免：

SO_REUSEADDR套接字选项来通知内核，如果端口忙，但TCP连接位于TIME_WAIT状态时可以重用端口

### 为什么客户端发送 ACK 之后不直接关闭？ ###

要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。


![](https://img-blog.csdnimg.cn/20190608160404569.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RyZWFtaXNwb3NzaWJsZQ==,size_16,color_FFFFFF,t_70)

## TCP粘包

### 什么是TCP粘包问题？

TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。

### 造成TCP粘包的原因

1. 发送方原因

   TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件

   - 只有上一个分组得到确认，才会发送下一个分组
   - 收集多个小分组，在一个确认到来时一起发送

   Nagle算法造成了发送方可能会出现粘包问题

2. 接收方原因

   TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

### 如何处理粘包现象？

1. 发送方

   使用**TCP_NODELAY**关闭Nagle算法

2. 接收方

   接收方没有办法来处理粘包现象，只能将问题交给应用层来处理

3. 应用层

   使用自定义协议+编码解码器

### UDP会不会产生粘包问题？

TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

### Nagle算法

TCP/IP协议中，无论发送多少数据，总是要在数据前面加上协议头，同时，对方接收到数据，也需要发送ACK表示确认。为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。

在建立TCP连接的同时，也可以确定发送数据包的单位，**最大段长度**（MSS）

Nagle算法指发送端即使还有应该发送的数据，但是如果数据很少的话，则进行延迟发送的一种处理机制。就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。**任意时刻，最多只能有一个未被确认的小段**

通过设置**TCP_NODELAY**将其禁用

## **滑动窗口**

为了解决TCP发送一次进行应答一次，引入窗口概念，窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

### 窗口大小由哪一方决定？

TCP 头里有一个字段叫 Window，也就是窗口大小。**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。所以，通常窗口的大小是由**接收方的决定的**。

## 为什么需要TCP流量控制？

双方在通信的时候，发送方的速率与接收方的速率是不一定相等，如果发送方的发送速率太快，会导致接收方处理不过来，这时候接收方只能把处理不过来的数据存在缓存区里。

如果缓存区满了发送方还在疯狂着发送数据，接收方只能把收到的数据包丢掉，大量的丢包会极大着浪费网络资源，因此，我们需要控制发送方的发送速率，让接收方与发送方处于一种动态平衡才好

## TCP流量控制

TCP协议通过滑动窗口来进行流量控制，它是控制**发送方**的发送速度从而使接受者来得及接收并处理。

接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为接收窗口大小

发送方收到之后，便会调整自己的发送速率，也就是调整自己发送窗口的大小，当发送方收到接收窗口的大小为0时，发送方就会停止发送数据

当发送方收到接受窗口 win = 0 时，这时发送方停止发送报文，并且同时开启一个定时器，每隔一段时间就发个测试报文去询问接收方，打听是否可以继续发送数据了，如果可以，接收方就告诉他此时接受窗口的大小；如果接受窗口大小还是为0，则发送方再次刷新启动定时器。

## TCP阻塞控制

拥塞控制是作用于网络，它是防止过多的包被发送到网络中，避免出现网络负载过大，网络拥塞的情况。控制的目的就是**避免「发送方」的数据填满整个网络。**

拥塞窗口 cwnd 变化的规则：

只要网络中没有出现拥塞，cwnd 就会增大；

但网络中出现了拥塞，cwnd 就减少；

### **慢启动（Slow Start）**

当建立新的TCP连接时，**拥塞窗口（congestion window,cwnd）**初始化为一个数据包大小。源端按cwnd大小发送数据，每收到一个ACK确认，cwnd就增加一个数据包发送量，这样cwnd就随着回路响应时间（Round Trip Time,RTT）的增加**呈指数增长**。

慢启动门限 ssthresh （slow start threshold）状态变量

- 当 cwnd < ssthresh 时，使用慢启动算法
- 当 cwnd >= ssthresh 时，就会使用「拥塞避免算法」

### 拥塞避免阶段(congestion avoidance)

每当收到一个 ACK 时，cwnd 增加 1/cwnd，由指数增长变为了线性增长

网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

当触发了重传机制，也就进入了「拥塞发生算法」

### 阻塞发生

 当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

- 超时重传（当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据）

- 快速重传（收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段）



当发生了「超时重传」，则就会使用拥塞发生算法。

- ssthresh 设为 cwnd/2
- cwnd 重置为 1

接着，就重新开始慢启动



当发生了「快速重传」（Fast Retransmit），则认为大部分数据没丢

- cwnd = cwnd/2 
- ssthresh = cwnd

接着，进入进入快速恢复算法

### 快速恢复(Fast Recovery)

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕

- 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）
- 重传丢失的数据包
- 如果再收到重复的 ACK，那么 cwnd 增加 1
- 如果收到新数据的 ACK 后，设置 cwnd 为 ssthresh，接着就进入了拥塞避免算法



## 为什么端口一共是*65535*个？如何确定？

TCP、UDP协议规定，使用2字节、16位来存储端口号，因此是0-2^16-1

确定端口号：

1. 标准既定端口号

   - 知名端口号

     0~1023

   - 某些正式注册端口号

     1024~49151

2. 时序（动态）分配

   49152~65535之间，每次在之前的基础上+1

## TCP定时器

1. 建立连接定时器(connection-establishment timer)

   建立连接的过程中，在发送SYN时， 会启动一个定时器(默认应该是3秒)，如果SYN包丢失了，那么3秒以后会重新发送SYN包的

2. 重传定时器(retransmission timer)

   重传定时器在TCP发送数据时设定，在计时器超时后没有收到返回的确认ACK，发送端就会重新发送队列中需要重传的报文段。

   1. 当TCP发送了位于发送队列最前端的报文段后就启动这个RTO计时器；
   2. 如果队列为空则停止计时器，否则重启计时器；
   3. 当计时器超时后，TCP会重传发送队列最前端的报文段；
   4. 当一个或者多个报文段被累计确认后，这个或者这些报文段会被清除出队列

3. 延迟应答定时器(delayed ACK timer)

   服务端收到客户端的数据后， 不是立刻回ACK给客户端， 而是等一段时间(一般最大200ms)，这样如果服务端要是有数据需要发给客户端，那么这个ACK就和服务端的数据一起发给客户端了， 这样比立即回给客户端一个ACK节省了一个数据包。

4. 坚持定时器(persist timer)

   为防止确认ACK丢失，接收方等待接收数据，而发送方在等待允许它继续发送数据的窗口更新，死锁情况的发生，发送方使用一个坚持定时器 (persist timer)来周期性地向接收方查询，以便发现窗口是否已增大。

5. 保活定时器(keepalive timer)

    在TCP连接建立的时候指定了SO_KEEPALIVE，保活定时器才会生效。如果客户端和服务端长时间没有数据交互，那么需要保活定时器来判断是否对端还活着，但是这个其实很不实用，因为默认是2小时没有数据交互才探测

6. FIN_WAIT_2定时器(FIN_WAIT_2 timer)

   主动关闭的一端调用完close以后（即发FIN给被动关闭的一端， 并且收到其对FIN的确认ACK）则进入FIN_WAIT_2状态。如果这个时候因为网络突然断掉、被动关闭的一段宕机等原因，导致主动关闭的一端不能收到被动关闭的一端发来的FIN，主动关闭的一段总不能一直傻等着，占着资源不撒手吧？这个时候就需要FIN_WAIT_2定时器出马了， 如果在该定时器超时的时候，还是没收到被动关闭一端发来的FIN，那么不好意思， 不等了， 直接释放这个链接

7. TIME_WAIT定时器 (TIME_WAIT timer, 也叫2MSL timer)

   TIME_WAIT是主动关闭连接的一端最后进入的状态， 而不是直接变成CLOSED的状态

## TCP和UDP的对比 ##

1. UDP在传输数据之前不需要先建立链接，TCP需要建立
2. UDP可以提供广播或多播服务，而TCP只能点对点服务
3. UDP传输效率快，需要资源少，但不可靠。TCP传输效率慢，需要资源多，可靠

## UDP如何实现可靠性传输？

 传输层无法保证数据的可靠传输，只能通过**应用层**来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。实现确认机制、重传机制、窗口确认机制。

## 浏览器中输入url地址 到 显示主页的过程

1. DNS解析
	- 浏览器缓存
	- 操作系统缓存
	- 本地hosts映射
	- 路由器缓存、DNS缓存
2. TCP连接
3. 发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析渲染页面
6. 连接结束

## ping的背后发生了什么？

ping命令依托于ICMP协议（为了更高效的转发，IP数据报和提高交付成功的机会）实现的，ARP协议

**同一个广播域内的ping：**

如host1想要去ping host2，host1会查看自己的MAC地址表，看看有没有host2的地址，如果没有就想外部发送ARP广播包（目的地址FF-FF-FF-FF-FF-FF）。

交换机收到报文后，会查询交换机上的MAC地址表

- 若有host2的MAC地址，直接返回给host1
- 若没有，交换机向所有端口发送ARP广播

其他端口上的主机发现以后，如果目标不是自己，就会丢弃报文，直到host2收到报文后，就会响应host2的MAC地址是多少，同时缓存host1的MAC地址，返回ARP报文给host1

此时host1知道了host2的MAC地址，于是发送ICMP报文，得到host2响应的ICMP报文

**不同广播域之间的ping：**

中间需要经过路由跳转

## DNS的过程

首先域名解析器会向域名服务器进行查询，接收这个查询请求的域名服务器首先会在自己的缓存进行查找

- 找到域名对应的IP地址就返回
- 找不到，先找根域的DNS，直到找到指定的域名服务器

解析器和域名服务器都会将最新了解的信息暂时保存在缓存中，减少性能消耗

浏览器就会发起一个DNS的系统调用，就会向本地配置的首选DNS服务器（一般是电信运营商提供的，也可以使用像Google提供的DNS服务器）发起域名解析请求（通过的是UDP协议向DNS的53端口发起请求，这个请求是递归的请求，也就是运营商的DNS服务器必须得提供给我们该域名的IP地址），运营商的DNS服务器首先查找自身的缓存，找到对应的条目，且没有过期，则解析成功。

如果没有找到对应的条目，则有运营商的DNS代我们的浏览器发起迭代DNS解析请求，它首先是会找根域的DNS的IP地址（这个DNS服务器都内置13台根域的DNS的IP地址），找到根域的DNS地址，就会向其发起请求（请问www.cnblogs.com这个域名的IP地址是多少啊？），根域发现这是一个顶级域com域的一个域名，于是就告诉运营商的DNS我不知道这个域名的IP地址，但是我知道com域的IP地址，你去找它去，于是运营商的DNS就得到了com域的IP地址

又向com域的IP地址发起了请求（请问www.cnblogs.com这个域名的IP地址是多少?）,com域这台服务器告诉运营商的DNS我不知道www.cnblogs.com这个域名的IP地址，但是我知道cnblogs.com这个域的DNS地址，你去找它去

于是运营商的DNS又向cnblogs.com这个域名的DNS地址（这个一般就是由域名注册商提供的，像万网，新网等）发起请求（请问www.cnblogs.com这个域名的IP地址是多少？），这个时候cnblogs.com域的DNS服务器一查，诶，果真在我这里，于是就把找到的结果发送给运营商的DNS服务器，这个时候运营商的DNS服务器就拿到了www.cnblogs.com这个域名对应的IP地址，并返回给Windows系统内核，内核又把结果返回给浏览器，终于浏览器拿到了www.cnblogs.com 对应的IP地址，该进行一步的动作了。


## DNS根服务器为什么只能有13个？

DNS协议决定的，它使用了端口上的UDP和TCP协议，UDP实现中保证正常工作的最大包长是512字节，要让所有的根服务器数据能包含在一个512字节的UDP包中，根据DNS报文的计算公式退出，根服务器只能限制在13个。

## 状态码 ##

1. 1xx：Informational，接收的请求正在处理 
	服务器就收客户端消息，但没有接受完成，等待一段时间后，发送1xx多状态码
2. 2xx：Success，请求正常处理完毕	
	代表：200
3. 3xx：Redirection重定向，需要进行附加操作以完成请求
	代表：302(重定向)，304(访问缓存)
4. 4xx：Client Error客户端错误，服务器无法处理请求
	代表：
	* 404（请求路径没有对应的资源） 
	* 405：请求方式没有对应的doXxx方法
5. 5xx：Server Error服务器端错误，服务器处理请求出错
	代表：500(服务器内部出现异常)

## HTTP请求报文结构

| 报文首部 |
| -------- |
| 空行     |
| 报文主体 |

**HTTP报文首部的结构**：由首部字段名和字段值构成的，中间用冒号“:”分割。首部字段格式： 首部字段名:字段值

请求行包括： 请求方法，URL(包括参数信息)，协议版本这些信息（GET /admin_ui/rdx/core/images/close.png HTTP/1.1）

请求头部(Header)是一个个的key-value值

| Header          | 解释                                                         | 示例                                           |
| --------------- | ------------------------------------------------------------ | ---------------------------------------------- |
| Accept          | 指定客户端能够接收的内容类型                                 | Accept: text/plain, text/html,application/json |
| Accept-Charset  | 浏览器可以接受的字符编码集                                   | Accept-Charse:                                 |
| Accept-Encoding | 浏览器可以支持Web服务器返回内容压缩编码类型                  | Accept-Language: en, zh                        |
| Connection      | 表示是否需要长连接                                           | Connection: close                              |
| Cookie          | HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器 | Cookie: $Version=1; Skin=new;                  |

空行(CR+LF)：请求报文用空行表示header和请求数据的分隔

请求数据：GET方法没有携带数据， POST方法会携带一个body


## http的请求头里有什么？

- Accept:浏览器能够处理的内容类型
- Accept-Charset:浏览器能够显示的字符集
- Accept-Encoding：浏览器能够处理的压缩编码
- Accept-Language：浏览器当前设置的语言
- Connection：浏览器与服务器之间连接的类型
- Cookie：当前页面设置的任何Cookie
- Host：发出请求的页面所在的域
- Referer：发出请求的页面的URL
- User-Agent：浏览器的用户代理字符串

## HTTP1.0 ##

1. 只需要传送请求方法和路径，简单快速
2. 数据格式灵活：http允许可以传输任意类型的数据
3. 使用短连接，客户端和服务器**每进行一次HTTP操作就建立一次连接**，任务结束就中断连接。
4. 无状态：每次连接在服务器都不会有记录

## HTTP1.1 ##
1. 默认使用长连接。当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的**TCP连接不会关闭**，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间
2. Host头：虚拟主机技术的发展使得一台服务器上可以有多个虚拟主机，它们可以共享同一个IP；
3. 请求范围：新增了PUT、DELETE、OPTIONS等请求方法；

## HTTP2.0 ##
1. 二进制传输

2. 多路复用

   一个TCP连接中存在多个流，可以同时发送多个请求

   帧是最小的数据单位，每个帧会标识出该帧属于哪个流

3. 头部压缩：请求头很多字段都是重复的，http2只需要根据索引id就可以进行传输，缩小了请求头的容量

4. 服务器推送：服务器可以主动向客户端推送资源

注：HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。

## HTTP是不保存状态的协议，如何保存用户状态？ ##
HTTP 是一种不保存状态，即无状态（stateless）协议。HTTP 协议自身不对请求和响应之间的通信状态进行保存。
**常见的有以下两种解决方案：**
1. 基于Session实现的会话保持
在会话开始时（客户端第一次向服务器发送http请求），服务器将会话状态保存起来（本机内存或数据库中），然后分配一个会话标识（SessionId）给客户端，这个会话标识一般保存在客户端Cookie中，以后每次浏览器发送http请求都会带上Cookie中的SessionId到服务器，服务器拿到会话标识就可以把之前存储在服务器端的状态信息与会话联系起来，实现会话保持（如果遇到浏览器禁用Cookie的情况，则可以通过url重写的方式将会话标识放在url的参数里，也可实现会话保持）
2. 基于Cookie实现的会话保持
基于Cookie实现会话保持与上述基于Session实现会话保持的最主要区别是前者完全将会话状态信息存储在浏览器Cookie中，这样一来每次浏览器发送HTTP请求的时候都会带上状态信息，因此也就可以实现状态保持。	

**两者优缺点：**
1. 基于Session的会话保持优点是安全性较高，因为状态信息保存在服务器端。缺点是不便于服务器的水平扩展。大型网站的后台一般都不止一台服务器，可能几台甚至上百台，浏览器发送的HTTP请求一般要先通过负载均衡器才能到达具体的后台服务器，这就会导致每次HTTP请求可能落到不同的服务器上，比如说第一次HTTP请求落到server1上，第二次HTTP请求落到server2上。而Session默认是存储在服务器本机内存的，当多次请求落到不同的服务器上时，上述方案就不能实现会话保持了（常用解决方案是中间件，例如Redis，将Session的信信息存储在Redis中，这样每个server就都可以访问到）
2. 基于Cookie的会话保持的优点是服务器不用保存状态信息，减轻服务端存储压力，也便于服务端做水平扩展。缺点是不够安全，因为状态信息是存储在客户端的，这意味着不能在会话中保存机密数据，另一个缺点是每次HTTP请求都需要发送额外的Cookie到服务端，会消耗更多带宽。

## HTTP和HTTPS的区别 ##
1. HTTP的URL"http://" 起始，HTTPS的URL"https://" 起始
2. HTTP协议运行在TCP上，明文传输，客户端和服务器都无法验证对方身份。HTTPS运行在SSL/TLS之上的HTTP协议，SSL/TLS运行在TCP上，所有的传输内容都经过加密
3. HTTP默认80端口，HTTPS默认443端口

## HTTPS进行SSL认证的过程

https是采用对称加密和非对称加密相结合的方式来进行安全认证的。对称加密用来加密所要发送的信息，非对称加密用来传输对称加密的秘钥算法等信息

首先，服务器把他的公钥和个人信息用Hash算法生成一个消息摘要，这个Hash算法有个好的特点就是只要输入的数据有一点点变化，那么生成的消息摘要就会发生巨变。 这样就可以防止别人修改原始的内容。然后再将这个消息摘要通过认证中心(CA)的私钥进行加密，形成**数字签名**。



## HTTPS、SSL、TLS三者之间的联系和区别

**SSL(Secure Socket Layer 安全套接层)**是基于HTTPS下的一个协议加密层，最初是由网景公司（Netscape）研发，SSL是基于HTTP之下TCP之上的一个协议层，是基于HTTP标准并对TCP传输数据时进行加密，所以HPPTS是HTTP+SSL/TCP的简称

在SSL更新到3.0时，IETF对SSL3.0进行了标准化，并添加了少数机制(但是几乎和SSL3.0无差异)，**标准化**后的IETF更名为**TLS1.0(Transport Layer Security 安全传输层协议)**，可以说TLS就是SSL的新版本3.1



## 网络通信方式

### 1. 电路交换

主要用于电话网，交换机负责数据的中转处理。

计算机发送数据时，需要通过交换机与目标主机建立通信电路

在一台计算机收发信息时会独占整个电路，其他计算机只能等待这台计算机处理结束后才能使用

### 2. 分组交换

如果将通信电路的计算机所发送的数据分成多个数据包，按照一定的顺序排列之后分别发送，就称为分组交换

数据被细分后，所有计算机就可以一齐收发数据，提高通信线路的利用率



## MAC地址和IP地址

MAC地址和IP地址在标识一个通信主体时都具有唯一性，但IP地址具有层次性（例如国家区号，国名，省名，市名）

MAC地址由设备的制造厂商针对每块网卡分别制定，但是**无法保证哪家厂商的哪个网卡被用到了哪个地方**，因此不具备层次性。

MAC地址负责最终通信的地址，但实际寻址过程中，却是使用的IP地址



## 网络设备

### 1. 中继器（Repeater）

中继器位于OSI模型第一层，是在物理层面上延长网络的设备，对减弱的信号进行波形调整和放大

有些中继器可以提供多个端口服务，也被称为**集线器**

### 2. 网桥（Bridge）

网桥位于OSI模型第二层，也称为L2交换机，负责连接两个网络的设备。

它能识别数据链路层中的数据帧，并将数据帧临时存储于内存，再重新生成信号作为一个全新的帧转发给相邻的另一个网段（通过MAC地址）

### 3. 路由器（Router）

路由器为与OSI模型第三层，也称为L3交换机，在网络层面上连接两个网络、并对分组报文进行转发。（通过IP地址）

### 4. 网关

网关是OSI模型中负责传输层到应用层的数据**转换**和**转发**的设备。在两个不能直接通信的协议之间进行翻译，最终实现两者通信



## 网络中传输的包结构

从前到后，大致有：

1. 以太网首部

   主要添加MAC地址，48位

2. IP包首部

   主要添加IP地址，（ip面向无连接）

3. TCP/UDP包首部

   主要添加端口号

4. 以太网包尾

   冗余校验

每个包的首部中至少两个信息：

- **发送和接收端的地址**
- **上一层的协议类型**



## ICMP

ICMP是（Internet Control Message Protocol）Internet控制报文协议。它是TCP/IP协议簇的一个子协议，用于在IP主机、路由器之间传递控制消息。属于**网络层协议**。

**IP协议并不提供可靠传输**，需要控制消息来保证是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。

ICMP协议的功能主要有： 

1. 确认IP包是否成功到达目标地址
2. 通知在发送过程中IP包被丢弃的原因 

## IPX

IPX (Internetwork Packet Exchange，互联网络数据包交换)  是指互联网分组交换协议，提供分组寻址和选择路由的功能，保证可靠到达，相当于数据报的功能。

对于IP协议来说，路由器的地址必须人为指定，IPX却是可以自动配置的

## DHCP

Dynamic Host Configuration Protocol协议，实现自动设置IP地址。统一管理IP地址的分配

使用DHCP之前，首先需要搭建一台DHCP服务器（常由路由器充当），分配方法：

1. 特定的IP地址中自动选出一个进行分配
2. 针对MAC地址分配一个固定IP地址

## NAT

Network Address Translator，是用户在本地网络中使用私有地址，在连接互联网时转而使用全局IP地址的技术，实际上是为正在面临地址枯竭的IPv4而开发的技术



## IP隧道

IPv4和IPv6之间无法直接通信，使用IP隧道来让他们之间正常通信



## 对称加密和非对称加密

原始数据（明文）利用某个值（密钥）通过加密算法变换成（密文），逆反过程叫做解密

- 对称加密：加密和解密使用相同的密钥

  AES（Advanced Encryption Standard）、DES（Data Encryption Standard）

- 非对称公钥加密：加密过程使用公钥，解密过程使用私钥

  RSA、DH（Diffie-Hellman）、椭圆曲线



## HTTPS

使用TLS/SSL的HTTP通信叫做HTTPS通信，HTTPS中采用对称加密方式，而再其发送公共密钥是采用的是公钥加密方式



## 短网址服务

短码方案是指将任意长度的url编码成新的固定长度的URL,并且新URL的长度要大大小于之前的URL。

假如原URL长度为20字符，短码使用5位字符方案，粗略计算的话，压缩比达到了 20^62 / 5^62之多，显然任何无损压缩是不可能达到这么高的比例的，我们知道比较好的压缩算法，可能最高也就是90%左右（比如对日志进行压缩时）。

因此方案必然是先进行摘要，然后对摘要值进行编码，然后建立编码结果到原网址的映射。

1. 用什么算法对原网址进行散列（摘要）？
2. 如何将散列值进一步转换（编码）成易识别、易输入的短码？

