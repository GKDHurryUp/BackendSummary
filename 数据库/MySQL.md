# MySQL #
## OLTP、OLAP ##
数据处理大致可以分成两大类：联机事务处理OLTP（on-line transaction processing）、联机分析处理OLAP（On-Line Analytical Processing）
OLTP 系统强调数据库内存效率，强调内存各种指标的命令率，强调绑定变量，强调并发操作；
OLAP 系统则强调数据分析，强调SQL执行市场，强调磁盘I/O，强调分区等。 

## 局部性原理 ##

指处理器在访问某些数据时短时间内存在重复访问，或者是访问邻近的数据。
缓存行：默认64个字节
缓存行越大，局部性空间效率越高，读取时间越慢
一个变量之间加Long p1-p7，之后加Long p8-p15
JDK8之后提供@Contended注解（需要加上-XX:-RestrictContended），被注释的字段将和其他字段隔离开来，会被加载在独立的缓存行上

因此我们可以一次性把该数据以及相邻的数据取到内存，就避免下一次取数据再到硬盘上取（进行IO操作），可以直接到内存中取

## MyISAM和InnoDB的区别 ##
1. 是否支持行级锁
	MyISAM只有表级锁，InnoDB支持行级锁和表级锁，默认行级锁
	
2. 是否支持事务和崩溃后的安全回复
	MyISAM强调性能，每次查询具有原子性，执行速度快，但不支持事务
	InnoDB支持事务，崩溃修复能力
	
3. 是否支持MVCC
    仅InnoDB支持，MVCC多版本并发控制，在READ_COMMITTED和REPEATABLE_READ下工作，它可以使用乐观锁或悲观锁来实现，各个数据库中MVCC实现并不统一

4. 是否支持外键
    仅InnoDB支持

5. 索引结构

   MyISAM非聚簇索引，InnoDB是聚簇索引

6. 存储总行数

   MyISAM存储了总行数，InnoDB需要全表扫描

## 为什么InnoDB不将总数存起来？

因为InnoDB支持事务，如果将总数存起来，无法保证各个事务之间的总数的一致性，因此InnoDB引擎在每个事务中返回多少行是不确定的，只能一行一行的读出来用来判断总数。

## InnoDB ##
页（Page）是InnoDB存储引擎用于管理数据的最小磁盘单位，默认大小为16KB
![](https://images2018.cnblogs.com/blog/919737/201804/919737-20180408162411775-1834436531.jpg)

1. File Header
	记录 Page 的头信息,FIL_PAGE_PREV 和 FIL_PAGE_NEXT 字段，通过这两个字段，可以找到该页的上一页和下一页
2. Page Header 
	记录 Page 的状态信息。
3. Infimum+Supremum 
	伪行记录，构成了页中记录的边界
4. User Records
	存放的是实际的数据行记录
5. Free Space
	存放的是空闲空间，被删除的行记录会被记录成空闲空间。
6. Page Directory
	记录着与二叉查找相关的信息
7. File Trailer 
	存储用于检测数据完整性的校验和等数据。

### 行格式 ###
1. COMPACT行格式
![](https://img-blog.csdn.net/20180706112109335?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1YW54aWFvYmluMjAxMA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
	- 变长字段长度列表
		- 变长字段中存储多少字节的数据是不固定的，我们在存储真实数据的时候需要顺便把这些数据占用的字节数存起来。
		- L变长字段长度列表，而且是按照列的顺序逆序放置的。当列的长度小于255字节，用1字节表示，若大于255个字节，用2个字节表示，变长字段的长度最大不可以超过2个字节
	- NULL标志位
		- 表明该行数据是否有NULL值。占一个字节。
	- 记录头信息
		- 固定占用5字节，其中 next_record 记录了下一条记录的相对位置，一个页中的所有记录使用这个字段形成了一条单链表
	- 隐藏列
		- DB_ROW_ID 行ID
			- 只有当用户没有指定主键，且表中没有 Unique 键时才会添加 DB_ROW_ID 作为主键
		- DB_TRX_ID 事务ID
		- DB_ROLL_PTR 回滚指针
2. Redundant
	没有NULL标志位，冗余存储
3. DYNAMIC行格式
	- 类似于COMPACT行格式，只不过在处理溢出数据时，**不会在记录的真实数据处存储一部分数据**，而是把所有的数据都存储到其他页面中，在记录**真实数据存储处存储其他页面的地址**
4. COMPRESSED行格式
	- COMPRESSED格式和DYNAMIC存储特性一样，同时提供了表和索引数据的**压缩处理**

## SQL语句的执行流程

![](..\imgs\sql执行流程.png)

1. 客户端发送一条查询给服务器
2. 服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段
3. 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划
4. MySQL根据优化器生成的执行计划，再调用存储引擎的API来执行查询
5. 将结果返回给客户端

## Select语句执行顺序

> **from**
>
> **join**
>
> on
>
> **where**
>
> **group by**
>
> avg，sum，count等各种函数
>
> having
>
> **select**
>
> distinct
>
> **order by**(asc(升序),desc(降序))
>
> LIMIT

LIMIT，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目

## 查看sql语句执行的时间

1. 设置SET profiling=1;
2. 执行完sql语句之后，SHOW PROFILES;

## **drop、truncate、delete区别与联系**

1. truncate 和 delete 只删除数据不删除表的结构，drop 语句将删除表的结构
2. delete 语句是数据库操作语言（DML），可以rollback，truncate、drop 是数据库定义语言（DDL），操作立即生效，不可以rollback 
3. truncate能够快速清空一个表，而delete只能一行一行的删除
4. 速度，一般来说: drop> truncate > delete

## exists和in的区别

1. exists是对外表做loop循环，每次loop循环再对内表（子查询）进行查询，那么因为**对内表的查询使用的索引**（内表效率高，故可用大表），而外表有多大都需要遍历，不可避免（尽量用小表），故内表大的使用exists，可加快效率；

2. in是把外表和内表做hash连接，先查询内表，再把内表结果与外表匹配，**对外表使用索引**（外表效率高，可用大表），而内表多大都需要查询，不可避免，故外表大的使用in，可加快效率。
3. not exists，子查询依然能用到表上的索引，效率高
4. not in ，则是内外表都全表扫描，无索引，效率低，并且如果出现了null结果为0

# 索引 #

按索引的存储来划分：
> 聚集索引（聚簇索引，唯一索引）
	索引页和数据物理**存储顺序**一致（字典拼音），也就是将数据存储与索引放到了一块
非聚集索引
	索引页和数据物理**存储顺序**不一致（字典偏旁），也就是将数据存储与索引分开，索引结构的叶子节点指向了数据的对应行

按照使用来分：
> 主键索引
唯一索引
辅助索引（普通索引）
联合索引（组合索引）
全文索引

注：默认会为主键和唯一键创建索引



MySQL索引使用的数据结构主要有：**BTree索引**和**哈希索引**
1. 哈希索引（**Memory支持**）:
	低层数据结构就是哈希表，绝大多数需求为单条记录查询时就可以选择哈希索引
缺点：
	1. 所有的数据文件需要添加到内存，比较耗费内存空间
	2. 只支持等值比较查询
	3. hash冲突，数据散列不均匀

2. BTree索引（B+Tree）
	- **MyISAM**：B+Tree叶节点的data域存放的是数据记录的地址。“非聚簇索引”
	- **InnoDB**：其数据文件本身就是索引文件。树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，InnoDB表数据文件本身就是主索引。“聚簇索引”
		- 在根据主索引搜索时，直接找到key所在的节点即可取出数据
		- 在根据辅助索引查找时，需要先取出主键的值，再走一遍主索引
		- 在设计表时，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键
		
## 主键索引（B+树特点） ##
实质上在插入的时候形成了一颗B+树
1. 一个节点内可以存多个数据（B树也是）
2. 所有数据存储在叶子节点，叶子节点有指针相连
3. 非叶子节点仅具有索引所用，跟记录有关的信息均存放在叶结点中

## B+树比B树优点 ##
1. B树不管是叶子节点还是非叶子节点，都会保存数据，导致在**非叶子节点中能保存的指针数量变少，会增加树的高度**，导致IO操作变多（磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多，一次IO多耗时）
2. **B+树的查询效率更加稳定**，所有查询都要查找到叶子节点，查询性能稳定；
3. 所有叶子节点形成有序链表，便于**范围查询**。
   -  B+树的范围查找，先二分查找得到下限，然后通过叶子节点的链表顺序遍历到上限即可。简单高效。
   - B树的范围查找，先二分查找得到下限，然后需要不断通过中序遍历，找到上限。比较耗时

## 一颗B+树可以存放多少行数据？

InnoDB底层的数据页大小默认为16KB，一般来说，生产环境一行数据为1KB左右，那么**一个数据页可以存放16条数据**。

InnoDB的一个页可以为索引页，也可以为数据页。对于索引页，存放主键和指针，注解一般使用**bigint**自增id为注解，大小为8B，指针一般为6B

则一个16KB的索引页可以存放16 * 1024 / 14 = 1170个单元

一般树高为3层，那么对应的数据页有1170^2个，则数据行数为**1170^2*16 ≈ 2000w**

## 为什么主键ID需要自增？  ##

1. 如果有序，链表在添加的时候只需要往尾部添加，不需要插入（断开链表）
2. 如果无序，插入的数据形成了很多页，会造成频繁的分页操作。而如果有序，只需要往链表后添加，页满了以后，只需要再新创建一个页就可以

## 为什么主键ID要比较小？ ##
1. 如果主键ID比较大，它所占用的空间也会变大，导致使用更多的页来存储数据，而一个页固定为16KB。第一浪费空间，第二导致B+树变深，查找变慢
2. **辅助索引也会包含主键列**，导致辅助索引存储空间很大

## 在插入时的优化 ##
在第一页满了一之后，不会直接开辟第二页，而是现将第一页复制一份，再开辟第二页，再把之前的第一页改变为目录页（如果这样操作的话，这个起始页是一直不变的，可以将它缓存起来，加载到内存中，加快查找速度）


## 辅助索引 ##
在创建辅助索引时候，会再创建一颗B+树，其叶子节点存储的是主键。
查找数据的时候会根据辅助索引树找到对应的主键，再根据主键找到对应的数据（回表）
1. 全值匹配
	- 如果通过辅助索引找到的**主键很多**（假如找出来的数量大于总共的80%），此时不如直接全表扫描
2. 最左前缀原理
	- 如果想要匹配某些字符串的后缀，如"LIKE %com",可以在插入数据的时候进行逆序存储一下，查找时候使用"LIKE moc%"就可以了

## 联合索引 ##
联合索引是以多个列的大小为排序规则建立的B+树称为联合索引，本质上也是一个辅助索引。如(a,b,c)实质是创建了(a,b,c)、(a, b)、（a）三个索引

**对于联合索引来说只不过比单值索引多了几列，并且这些索引列全都出现在索引树上**

命名规则：

1. 需要加索引的字段，要在where条件中
2. 数据量少的字段不需要加索引
3. 不能使用索引**范围条件**右边的列
4. 如果where条件中是OR关系，加索引可能不起作用
5. 符合最左原则

尽量将选择性最高的列放在索引最前面

select * from myTest where a=3 and **b>7** and c=3; a用到了，b也用到了，c没有用到  **---- b范围值，断点，阻塞了c的索引**

 select * from myTest where **a>4** and b=7 and c=9;  a用到了  b没有使用，c没有使用

### 什么时候创建联合索引？

当我们的where查询存在多个条件查询的时候，我们需要对查询的列创建组合索引

1. 减小开销

   查询字段在索引页中，那么可以直接从索引中直接获取，不需要回表，也就是索引覆盖

2. 效率高

   若果分别建立单个索引，只会选择辨识度最高的一列作为索引，而组合索引都可以用到

## 全文索引 ##
用于关键字的匹配来进行查询过滤，在大量的数据面前，能比 like + % 快 N 倍

只有字段的数据类型为 char、varchar、text 及其系列才可以建全文索引。

使用：

	select * from fulltext_test 
		where match(content,tag) against('xxx xxx');

MySQL 5.7.6 开始，引入了一个 ngram 全文分析器来解决汉语等文字

由于表级别锁对性能的影响、数据文件的崩溃、崩溃后的恢复等，常使用第三方插件：Sphinx、Lucene 等

## 索引的专业词汇 ##
### **覆盖索引**：

在通过辅助索引查询时，若其查询的字段同时包含在一个索引中，如主键索引和辅助索引，可以直接返回，不经过**回表**

### **索引下推**：using index condition

mysql5.6添加

1. 先从存储引擎把所有符合第一个条件的数据拉取回来，再在server层进行其它条件的筛选（未使用）
2. 从存储引擎拉取数据的时候已经把所有条件进行了筛选（使用）

### **谓词下推**：

将过滤表达式尽可能移动至靠近数据源的位置，以使真正执行时能直接跳过无关的数据。优化器会自动去帮我们做这种优化

### 唯一索引：

创建唯一约束，会自动创建一个同名的唯一索引，该索引不能单独删除，删除约束会自动删除索引。唯一约束是通过唯一索引来实现数据的唯一。

## 唯一索引和普通索引怎么选择？

其实，如果业务上就要求我们数据库的值必须是唯一的，那没什么好讨论的，就选择唯一索引

### 查询性能

从 B+树的叶子节点进行按层搜索，定位到我们数据在的数据页，数据页内基本按照二分法查找我们具体要查找的数据。

- 普通索引：查找到满足条件的值后，需要进一步查找，直到不满足条件为止

- 唯一索引：找到需要查找的值后，由于唯一索引，所以只有一个值，所以可以直接返回

但是影响并不大，是因为我们读取数据的时候都是按照数据页去读取的， 一个数据页默认大小为 16K，可以存上千个索引值。那普通索引的移动指针到下一个元素和比较的数据都是在内存中的，所以影响比较小。

### 更新性能

Mysql 的数据包含两个部分，一部分在内存中，一部分在磁盘上，在内存中的不光是 Mysql 的数据还有索引。

我们在更新的时候，如果数据在内存里面好说，直接更新，定期刷新到磁盘，但是更多的时候可能是数据不在内存中，如果每次都从磁盘读取数据所在的数据页，然后去操作，就需要至少涉及到一次磁盘的随机读操作，比较昂贵的操作。

Mysql 中有一块内存就叫 change buffer，在内存里面中把这个更新操作纪录下来，在合适的时候再将数据合并到磁盘上。

数据页在内存中：

- 普通索引：则直接更新内存中的数据
- 唯一索引：插入操作，将需要插入的字段值和数据页中的比较看是否存在，决定是否可以插入

差别很小

数据页不在内存中：

- 普通索引：在 change buffer 中记录对那个数据页做了什么样的修改
- 唯一索引：则需要将数据页读取到内存中，判断是否满足唯一性约束，不会使用change buffer

从更新角度看，**普通索引**可以利用 **change buffer 更新操作**的性能比**唯一索引**要更好。

### change buffer的使用场景

将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。

因为merge的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

因此，对于**写多读少**的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好，这种业务模型常见的就是账单类、日志类的系统。

反过来，假设一个业务的更新模式是**写入之后马上会做查询**，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价，所以，对于这种业务模式来说，change buffer反而起到了副作用。

## 自适应哈希索引

当InnoDB引擎注意到某些索引值被使用的非常频繁时，他会在内存中基于B+树索引之上，再创建一个哈希索引，

## 什么时候索引会变慢？ ##

1. 过多的建立了索引，索引也成为了数据文件
2. 建立索引的字段大多操作是非查询，频繁变动

## 索引什么时候会失效？ ##

1. **like '%ad%'**
2. 组合索引如果中间某一个值使用了范围查询
3. **使用函数的时候**
4. 使用表达式的时候 where id+1=4
5. 类型不匹配，涉及隐式转换时（函数强转类型）
6. 数据量特别大的时候也会失效
7. or在某些情况下会失效

## 什么是索引的基数？

基数又叫索引基数，是数据列所包含的不同值的数量。索引基数越大，工作效率越好。如果某个索引所在的数据列只记录性别(man或者woman)，那么索引的用处就不大。

# join #

大致分为内连接，自然连接，外连接(右连接，左连接，全连接)

![](https://img-blog.csdnimg.cn/20190509115843374.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01yc19jaGVucw==,size_16,color_FFFFFF,t_70)

## left join和right join的区别

left join是左连接，查出来的结果显示左边的所有数据，然后右边显示的是和左边有交集部分的数据，若无显示null

## 自然连接 ##

自然连接是通过对参与表关系中所有**同名的属性**对取等（即相等比较）来完成的，故**无须自己添加连接条件**

## 内连接 ##
内连接与自然连接基本相同，不同之处在于自然连接只能是同名属性的等值连接，而内连接可以使用using或on子句来指定连接条件，连接条件中指出某两字段相等（可以不同名）。

## 使用join时on和where的区别

1.  on条件是在生成临时表时使用的条件
2. where条件是在临时表生成好后，再对临时表进行过滤的条件

## join有几种实现方式？ ##

MySQL只支持一种join算法：Nested-Loop Join（嵌套循环连接），但Nested-Loop Join有三种变种
1. Simple Nested-Loop Join（SNLJ）算法：
**嵌套循环算法**，循环外层是驱动表，循坏内层是匹配表，驱动表会驱动匹配表进行连接操作。（双重循环）
2. Index Nested-Loop Join（INLJ）算法：
首先要求匹配表上有索引，可以通过索引来减少比较，加速查询。在查询时，驱动表会根据关联字段的索引进行查找，挡在索引上找到符合的值，再回表进行查询（如果主键索引不需要回表）
2. Block Nested Loop Join(BNLJ)算法：
**块嵌套循环算法**，是对NLJ的优化。大致思想就是建立一个缓存区，一次从驱动表中取多条记录，然后扫描被驱动表，被驱动表的每一条记录都尝试与缓冲区中的多条记录匹配，如果匹配则连接并加入结果集。

## 编码 ##
MySQL中utf8默认是0-3字节，与平常不不一样
utf8mb4是0-4字节，与常用的utf8一样



# 调优

首先分为两个层次，server层和引擎层

server层：

- 连接器，对于连接器可以通过建立连接池来进行优化。连接器进行连接的时候会消耗资源，还会进行权限验证等操作，为了避免频繁创建连接，所以使用连接池。
- 缓存模块，使用缓存进行查询优化，查询缓存的失效非常频繁，只要有对一个表的更新，这个表上的所有的查询缓存都会被清空。mysql8.0去掉
- 分析器，进行语法分析之类
- 优化器，对sql语句进行优化，生成执行计划
- 执行器

引擎层：

- 优化SQL语句
- 创建索引

## SQL语句优化

1. 避免SELECT *，它会取到一些我们不需要更多的数据，造成更大的网络开销

2. 使用count(*)

   mysql优化器会进行优化，去遍历最小的索引树（普通索引）

3. join连接表

   - 小表驱动大表，也就是数据量小的表作为主表进行连接
   - 连表条件增加索引
   - 在没有索引，并且驱动表数据量过大时，可以通过调大join_buffer_size的值来加速连表查询。

4. 查询单条记录

   加上limit 1，防止多条相同的记录向后继续查询

索引相关：

1. 覆盖索引

   使用覆盖索引，避免回表查询

2. order by字段建立索引

   索引是有序的，不需要排序，排序时候直接走有序索引就避免了排序过程

3. like查询

   尽量不要以通配符开头

4. 最左前匹配原则

   

## 调优步骤

1. 首先找到慢SQL语句，可以使用阿里RDS控制台，show status

2. 排除缓存干扰，在NoCache去跑SQL。

   一旦对表进行更新，表的所有缓存都会被清空

3. 先去涉及SQL业务的本地环境跑一遍SQL，用explain查看一下执行计划，查看是否符合自己的预期，是否使用了相关索引，是否使用索引下推

## 数据库优化 ##
1. 设计数据库时：数据库表、字段的设计，存储引擎
2. SQL语句的优化（收效甚微）
3. 利用好MySQL自身提供的功能，如索引等
4. 横向扩展：MySQL集群、负载均衡、读写分离

字段设计：
1. 尽量使用整型表示字符串	
2. 尽可能选择小的数据类型和指定短的长度（缩减页深度）
3. 尽可能使用 not null（记录null需要额外的空间）
4. 表要设置主键并自增 ID 值

尽量使用索引：
1. order by，使用索引
2. join语句涉及的字段使用索引
3. like查询时，尽量不要以通配符开头，无法利用索引

## Explain命令 ##
explain + sql语句， 查看执行计划

> id: 选择标识符
> select_type: 表示查询的类型。
> table: 输出结果集的表
> partitions: 匹配的分区
> type: 表示表的连接类型
> possible_keys: 表示查询时，可能使用的索引
> key: 表示实际使用的索引
> key_len: 索引字段的长度
> ref: 列与索引的比较
> rows: 扫描出的行数(估算的行数)
> filtered: 按表条件过滤的行百分比
> Extra: 执行情况的描述和说明

1. 表的读取顺序
2. 数据读取操作的操作类型
3. 哪些索引可以使用
4. 哪些索引被实际使用
5. 表之间的引用
6. 每张表有多少行被优化器查看

### 统计这个统计的行数就是完全对的么？

MySQL中数据的单位都是页，MySQL又采用了采样统计的方法，采样统计的时候，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。

解决：用analyze table tablename 就可以重新统计索引信息了

### 索引一定会走到最优索引么？

假设两个索引，A索引要扫描100行，B只要20行。一般出现这种情况都是**覆盖索引**，因为优化器在选择的时候发现，走A索引没有额外的代价，比如走B索引并不能直接拿到我们的值，还需要回表。所以它会选索引A

解决：使用force index强制走正确的索引，或者新建索引

## 大表优化 ##
1. 限定数据的范围
	禁止不带任何限制数据范围条件的查询语句
2. 读/写分离
	主库负责写，从库负责度
3. 垂直分区
	根据数据库里面数据表的相关性进行拆分，如根据数据表的列拆分，把一张列比较多的表拆分为多张表
	- 优点：查询时减小读取的Block数，减少I/O次数，简化表结构
	- 缺点：主键冗余，引起Join操作，让事务变复杂
4. 水平分区
	保持数据表结构不变，通过某种策略存储数据分片，水平拆分最后分库

## 分库分表之后，id主键如何处理？ ##
使用全局唯一的id来表示
1. UUID（Universally Unique Identifier）
	不适合，过长，并且无序
2. 数据库自增id
	两台数据库分别设置不同步长，生成不重复ID策略
3. 利用redis生成id
	incr命令，性能比较好，灵活方便，不依赖与数据库。但是引入心的组件造成系统更加复杂
4. Twitter的snowflake算法
5. 美团的Leaf分布式ID生成系统

## 什么是数据库连接池？为什么需要？ ##
池化设计思想：

其实是一个种享元设计模式，常见的如java线程池、jdbc连接池、redis连接池，这种设计会初始预设资源，解决的问题就是抵消每次获取资源的消耗，避免与操作系统频繁，如创建与销毁线程的开销。

数据库连接本质就是一个socket连接。就需要到网卡上加载数据，因此就涉及到了用户态和内核态的切换。数据库服务端还要维护一些缓存和用户权限信息之类的，所以占用了内存。我们可以把数据库连接池看做是维护的数据库连接的缓存，以便需要对数据库的请求时可以重用这些资源。为每个用户打开和维护数据库连接，即昂贵又浪费。在连接池中，创建连接后，将其放置在池中，并再次使用它，因此不必建立新的连接。

# 事务
事务是逻辑上的一组操作，要么都执行，要么都不执行
## 事务四大特性ACID ##
1. 原子性（Atomicity）：
	事务是最小的执行单位，不能分割。要么全部成功，要不全部失败
2. 一致性（Consistency）
	执行事务前后，数据保持一致，多个事务对同一个数据读取结果相同
3. 隔离性（Isolation）
	并发事务之间数据库是独立的，一个事务不会被其他事务所干扰
4. 持久性（Durability）
	事务一旦被提交，数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响

## 并发事务带来哪些问题？ ##
1. 脏读（Dirty read）
	一个事务修改数据，但未提交，但另一个事务读到了修改后的数据
2. 丢失修改（Lost to modify）
	一个事务修改数据，另一个事务也修改这个数据。第一个事务内的修改结果被丢失
3. 不可重复度（Unrepeatable read）
	一个事务内多次读取同一个数据，另一个事务修改了这个数据。第一个事务两次读数据可能不一样
4. 幻读（Phantom read）
	一个事务读取了几行数据，另一个事务插入了一些数据。随后查询中，第一个事务会多了一些原本不存在的记录

## 事务隔离级别有哪些？ ##
1. READ-UNCOMMITTED：**读未提交**
	* 产生的问题：脏读、不可重复读、幻读
2. READ-COMMITTED：**读已提交** （Oracle）
	* 产生的问题：不可重复读、幻读
3. REPEATABLE-READ：**可重复读** （MySQL默认）
	* 产生的问题：幻读
4. SERIALIZABLE：**可串行化**
	完全服从ACID，所有的事务依次逐个执行

注：

- RR级别下，mvcc解决了不可重复读的问题，但是依然会存在幻读问题，要杜绝幻读，必须显式加锁，对于唯一索引单条记录加的就是record lock，对于非唯一索引加的就是next key lock

- 在分布式事务下，一般使用REPEATABLE-READ（可串行化）隔离级别

## READ-COMMITTED 原理 ##
在行格式里有一个隐藏列，里面有DB_TRX_ID（事务ID），DB_ROLL_PTR（回滚指针）

在修改的事务中，会保存修改的值（自己会读取到自己的值），形成一个版本链，通过回滚指针，配合undo日志，指向上一个修改了的事务（每个事务都有自己的ID）

对于想要读取值的事务，会生成一个readView，里面m_ids记录了活跃的事务的ID（未提交），**若有事务提交m_ids则去除该事务的ID**，根据这个m_ids通过版本链就可以得到读取到已提交的事务

## REPEATABLE-READ 原理 ##
对于想要读取值的事务，会生成一个readView，里面m_ids记录了活跃事务的ID（未提交），**若有事务提交m_ids不会去除该事务的ID，也就是只生成一次**，根据这个m_ids通过版本链就可以得到读取到已提交的事务

## 当前读和快照读 ##
1. 像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读。它取名含义就是读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。
2. 像不加锁的select操作就是快照读，即不加锁的非阻塞读

## MVCC多版本并发控制 ##
可以使得我们在执行普通的SELECT操作时，不去使用锁，提高并发性能。MVCC支持READ-COMMITTED、REPEATABLE-READ两种隔离级别。

原理：

在行格式里有一个隐藏列，里面有DB_TRX_ID（事务ID），DB_ROLL_PTR（回滚指针）

在执行修改、增加、删除操作时，会生成对应的事务ID，然后会把这个行数据复制一份到undo日志中，使得回滚指针指向复制的行数据

在执行select查询sql时，会生成一致性视图read-view，它由执行查询操作时，所有==未提交事务id数组==（数组里最小的id为min_id）和已创建的最大事务id（max_id）组成，查询的数据结果需要跟read-view做对比从而得到快照结果

1. READ-COMMITTED：
**在每进行一次**普通SELECT操作前都会生成一个ReadView
2. REPEATABLE-READ：
**在第一次**进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView

## binlog、undolog、redolog

- redo log是InnoDB存储引擎层的日志，又称重做日志文件，用于记录事务操作的变化，**记录的是数据修改之后的值**，不管事务是否提交都会记录下来
- undo log保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读

- binlog是属于MySQL Server层面的，又称为归档日志，属于逻辑日志，是以二进制的形式记录的是这个语句的原始逻辑


# 锁 #

- 表锁：开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低
- 行锁：开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高
- 页锁：开销和加锁速度介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般（InnoDB中不支持，BDB中支持）

## 行锁 ##

==只有通过索引条件检索数据，InnoDB才使用行级锁==，否则，InnoDB将使用表锁

### 记录锁（Record Lock）

行锁锁定的是索引记录，而不是行数据，也就是说锁定的是key

### 临键锁（Next-Key Locks）

也称后码锁，记录锁和间隙锁的结合，可以解决幻读问题

每个数据行上的**非唯一索引列**上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段**左开右闭区间**的数据。需要强调的一点是，InnoDB中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在**临键锁**。

### 间隙锁（Gap Lock）

查询时，没有匹配记录会降级为间隙锁

 一般是针对非唯一索引而言的，更新一条数据行时，会找到它索引对应的值，对它上下两个区间进行锁定，同时找到数据对应的主键索引和非唯一索引，对key加锁

## 表锁 ##

在对某个表执行ALTER TABLE、DROP TABLE这些DDL语句时，其他事务对这个表执行SELECT、INSERT、DELETE、UPDATE的语句会发生阻塞。或者，某个事务对某个表执行SELECT、INSERT、DELETE、UPDATE语句时，其他事务对这个表执行DDL语句也会发生阻塞，这个过程使用的是元数据锁（Metadata Locks，MDL）来实现的，而不是使用表级别的S锁和X锁

## S锁和X锁 ##

S锁也称为**共享锁、读锁**，X锁也称为**排它锁、写锁**

### 读操作

1. select ... lock in share mode
   会将查到的数据加上一个S锁，允许其他事务继续获取这些记录的S锁，不能获取这些记录的X锁（阻塞）

   使用场景：读到数据后，其他事务不能修改，但是自己也不一定能修改，因为其他事务也可以使用该语句继续加读锁

2. select ... for update
   将查找到的数据加上一个X锁，不允许其他事务获取这些记录的S锁和X锁

   使用场景：读到数据后，其他事务既不能写，也不能加读锁，只有自己可以修改数据

### 写操作 ###

1. DELETE
   删除一条数据使，先对记录加X锁，再执行删除操作
2. INSERT
   插入一条记录时，会先加**隐式锁**来保护这条新插入的记录在本事务提交前不被别的事务访问到
3. UPDATE
   - 如果被更新的列，修改前后没有导致存储空间发生变化，那么会先给记录加X锁，再直接对记录进行修改
   - 如果被更新的列，修改前后导致存储空间发生了变化，那么会先给记录加X锁，然后将记录删除掉，在Insert一条新记录

## IS锁、IX锁 ##

如果一个表中某个行加了锁，此时是不能给表加锁的。如果在给表加锁之前，对每行数据判断是否有行锁存在，会有很大的开销
1. IS锁：Intention Shared Lock 意向共享锁
	当事务准备在某条记录上加S锁时，需要先在表级别加一个IS锁
2. IX锁：Intention Exclusive Lock 意向排他锁
	当事务准备在某条记录上加X锁时，需要先在表级别加一个IX锁
- IS、IX锁是表级锁，它们的提出仅仅为了在之后加表级别的S锁和X锁时**可以快速判断表中的记录是否被上锁**，以避免用遍历的方式来查看表中有没有上锁的记录

## 自增锁

**5.1.22之前**，InnoDB自增值是通过其本身的自增长计数器来获取值，当表里有一个auto_increment字段的时候，innoDB会在内存里保存一个**计数器**用来记录auto_increment的值，当插入一个新行数据时，就会用一个**表锁来锁住这个计数器**，直到插入结束。如果大量的并发插入，表锁会引起SQL堵塞

**5.1.22之后**，InnoDB为了解决自增主键锁表的问题，引入了参数**innodb_autoinc_lock_mode**，该实现方式是通过**轻量级互斥量的增长机制**完成的，它可以设定3个值，0，1，2

> 0：traditonal 通过表锁的方式进行,所有类型的insert都用AUTO-inc locking。
>
> 1：consecutive 默认值，产生一个轻量锁，对于simple insert 自增长值的产生使用互斥量对内存中的计数器进行累加操作，对于bulk insert 则还是使用表锁的方式进行。（默认）
>
> 2：interleaved 对所有的insert-like 自增长值的产生使用互斥量机制完成，并发性能最高，并发插入可能导致自增值不连续，可能会导致Statement 的 Replication 出现不一致，使用该模式，需要用 Row Replication的模式。

总结：当innodb_autoinc_lock_mode为0时候， 自增id都会连续，但是会出现表锁的情况，解决该问题可以innodb_autoinc_lock_mode 设置为1，甚至是2。会提高性能，但是会在一定的条件下导致自增id不连续。

## 获取InonoD行锁争用情况

可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况：

```sql
mysql> show status like 'innodb_row_lock%';
```

## 死锁 ##

1. 不同表相同记录行锁冲突

  一个用户A 访问表A(锁住了表A),然后又访问表B；另一个用户B 访问表B(锁住了表B)，然后企图访问表A；这时用户A由于用户B已经锁住表B，它必须等待用户B释放表B才能继续，同样用户B要等用户A释放表A才能继续，这就死锁就产生了

  解决方法：由于程序的BUG产生，对于数据库的多表操作时，尽量按照相同的顺序进行处理，尽量避免同时锁定两个资源

2. 相同表记录行锁冲突

  用户A查询一条纪录，然后修改该条纪录；这时用户B修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而用户B里的独占锁由于A 有共享锁存在所以必须等A释放掉共享锁，而A由于B的独占锁而无法上升的独占锁也就不可能释放共享锁，于是出现了死锁。

  解决方法：
  1. 对于按钮等控件，点击后使其立刻失效，不让用户重复点击，避免对同时对同一条记录操作。
  2. 使用乐观锁进行控制。即为数据增加一个版本标识，为数据库表增加一个“version”字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。
  3. 使用悲观锁进行控制。依靠数据库的锁机制，Select … for update

3. 在事务中执行了一条不满足条件的update语句，则执行全表扫描，把行级锁上升为表级锁，多个这样的事务执行后，就很容易产生死锁和阻塞。或者是表中的数据量非常庞大而索引建的过少或不合适的时候，使得经常发生全表扫描

### 如何降低死锁发生概率？

1. 设置锁优先级：提前设置优先级，如果运行A和B出现死锁，优先级低的回滚，优先级高的先执行，这样即可解决死锁问题
2. 以固定顺序访问：设定一个顺序，比如先A后B，或者先B后A，保证不管在什么时候都尊重这个顺序（通常是按ID大小的顺序），这样就会减少死锁发生的概率了
3. 设置锁超时时间set lock_timeout，尝试获取锁的时候加一个锁超时时间，超过这个时间放弃对该锁请求
4. 每一个事务一次就将所有要使用到的数据全部加锁

### wait-for graph

innodb将各个事务看为一个个节点，资源就是各个事务占用的锁，当事务1需要等待事务2的锁时，就生成一条有向边从1指向2，最后行成一个有向图，检测这个有向图是否出现环路即可，出现环路就是死锁

# MySQL主从复制 #
## 为什么要做主从复制？ ##
1. 有一句sql语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运行
2. 做数据的热备，主库宕机后能够及时替换主库，保证业务可用性
3. 架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。

## MySQL主从复制的流程 ##
1. 主库db的更新事件(update、insert、delete)被写到binlog
2. 主库创建一个binlog dump thread，把binlog的内容发送到从库
3. 从库启动并发起连接，连接到主库
4. 从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log
5. 从库启动之后，创建一个SQL线程，实时监控并从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db

