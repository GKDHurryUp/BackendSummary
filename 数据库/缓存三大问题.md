## 为什么要使用缓存？ ##
1. 提高性能
	一般使用redis作为缓存，它是运行在内存中的，不会进行IO操作，速度会快很多
2. 保护数据库
	

## 缓存预热 ##
服务器启动后迅速宕机，服务器刚启动时，缓存中没有数据，而此时请求数据量比较高。
缓存预热就是系统启动前，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库,然后再将数据缓存的问题!用户直接查询事先被预热的缓存数据!

解决：
1. 前期：
	- 日常例行统计数据访问记录，统计热点数据
	- 使用LRU数据删除策略，构建数据存留队列
2. 准备工作：
	- 将统计数据分类，优先加载热点数据
	- 利用分布式多服务器同时数据读取
3. 实施：
	- 使用脚本程序固定触发数据预热
	- CDN（内容分发网络）

## 缓存穿透 ##
**根本没有这个数据**，查询数据库没有的数据，缓存也没有

解决：
1. **缓存空对象**
	代码简单，效果不是很好
	每次**访问一个不存在的数据**，都需要查询一次数据库
	会有很多**空对象**存储在数据库中
2. **布隆过滤器**
	代码维护非常复杂，效果很好
	数据库添加，布隆过滤器也需要添加
	数据库删除，布隆过滤器是没有办法删除的，如果数据库删除过多的话，需要重建

## 布隆过滤器 ##
本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure）,可以用表示 “某样东西一定不存在或者可能存在”

布隆过滤器应用：
存东西的集合（类似于List），只有put方法（添加的时候直接改变1，会覆盖之前的信息，不保存），mightContain方法
有误判概率（可以定义）

## 布隆过滤器原理 ##	
底层使用位数组，占用1bit，只有0或者1
使用个不同个数的hash函数对字符串进行计算，再对数组长度取余（位运算代替），计算出位数组的索引下标
容错概率跟数组长度，与hash函数个数相关，容错率越高，数组越短，hash函数越少

## Google布隆过滤器和Redis布隆过滤器 ##
1. guava的布隆过滤器，是存在JVM内存的，数据不会持久化，位数组长度最多21亿
2. redis中，redis内存，数据会持久化，位数组长度最多42亿
redis中，字符串使用二进制存储，也就是位数组512M转换为位就是42亿（ 8 * 1024 * 1024 * 512 = 2^32 ）
3. redis可以使用分布式

## 使用布隆过滤器的问题 ##
1. 数据库添加数据，布隆过滤器也需要添加数据
2. 数据库删除一条数据，布隆过滤器可以不用管（不能删除），但是数据库删除的数据多的话，需要重新构建布隆过滤器

## 缓存击穿
**查询数据库有的数据**，**缓存没有的数据**，一般热点数据 并发访问	

1. 没人访问该条数据
2. 设置过期时间， 数据刚好失效

解决：
1. 加分布式锁
	在查询数据库时加分布式锁（只锁查询的id），在查询数据库之前再次判断缓存
2. 设置二级缓存，保证不被同时淘汰
3. 手动调整热点数据过期时间

注：如果是中小型公司项目，MySQL没那么脆弱，一条热点数据不会让MySQL挂掉，基本上不需要处理。而如果是大型项目，特别高的并发量，会击穿MySQl，需要加锁保护




## 缓存雪崩
和缓存击穿不同的是， 缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到缓存从而查数据库。

1. redis宕机 
	解决：redis高可用集群cluster ，将热点数据均匀分布在不同搞得缓存数据库中

2. 缓存中大部分数据失效
	错开数据失效时间，防止同一时间大量数据过期现象发生。
	设置热点数据永远不过期。

解决方案：
1. LRU与LFU切换
2. 数据失效期错峰
3. 超热数据使用永久key
4. 定期维护，配合统计量，进行热点数据的延时
### 如果已经出现雪崩该怎么办？ ###
1. 熔断
2. 限流


# 数据一致性问题，数据库与缓存
缓存信息本质上是硬盘数据的副本，归根结底是一种空间换时间的技术，数据一致性问题是不可避免的

## 更新缓存与更新数据库的关系 ##

1. 先删除缓存，在更新数据库【错误】

   假设两个并发操作，一个查询一个更新，更新操作删除缓存后，查询操作没有命中缓存，把旧数据放入缓存中，导致缓存中一直存放的是旧数据

2. ==先更新数据库，成功后，删除缓存== （**Cache Aside Pattern**）

   此方案也会发生并发问题，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。

   但是理论上会出现，不过非常低的概率会发生，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。

严格要求缓存+数据库一致性，就是读请求和写请求串行化，串行到一个内存队列里去，

### Cache Aside Pattern方案有什么问题？

如果先操作数据库，再淘汰缓存，在原子性被破坏时：

（1）修改数据库成功了

（2）淘汰缓存失败了

导致，数据库与缓存的数据不一致

## 缓存一致性解决方案 ##

1. 数据实时同步更新
	- 优点：强一致性，更新数据库同时更新缓存（配置AOP），不会出现缓存雪崩
	- 缺点：运行耦合，缓存服务器宕机，整个业务失效，并且增加一次网络开销
	- 应用场景：适合写操作频繁的细粒度缓存数据，数据一致实时性比较高的场景，银行业务、证券交易	

2. 数据准实时更新
	- 实现：通过中间消息队列MQ，通过一个缓存更新服务，异步更新缓存
	- 优点：数据与业务解耦，不影响正常业务，不会出现缓存雪崩问题
	- 缺点：有较短延迟，无法保证最终一致性，需要补偿机制

3. 缓存实现机制
	- 实现：基于缓存本身失效机制
	- 优点：实现简单，不影响正常业务
	- 缺点：有一定延迟，存在缓存雪崩问题
	- 应用场景：不适合写操作频繁，适合读多写少的互联网场景。电商业务，理财金融，社交业务

4. 任务调度更新
	- 实现：最终一致性，按一定频率更新
	- 优点：不影响正常业务
	- 缺点：不保证一致性，代码复杂
	- 应用场景：适合复杂统计类数据缓存更新，如BI分析，统计类数据

## redis指令与命令监控 ##
1. redis-beachmark指令，实现压测效果
2. monitor个命令，打印服务器调试信息
3. slowlog命令
	- slowlog-log-slower-than，设置慢查询时间下限
	- slowlog-max-len，设置慢查询日志显示长度