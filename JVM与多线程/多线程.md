## 线程、进程、协程 ##
1. 进程是程序在计算机上的一次执行活动，是系统运行程序以及进行资源分配和调度的基本单位
2. 线程是CPU的基本执行单元，一个线程属于一个进程。在一个进程中，会有多个线程同时执行，共享进程的数据空间（堆和方法区），但每个线程也有自己的空间（程序计数器、虚拟机栈、本地方法栈）
3. 协程，是一种比线程更加轻量级的存在。协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。（Java需要使用kilim框架）

## 超线程 ##
一个实体CPU中，提供两个逻辑线程，在CPU内，一个ALU（整数运算单元）对应多个PC|Registers

## 线程的基本状态 ##

1. NEW
	初始状态，线程被构建，但没有掉用start()方法
2. RUNNABLE
	运行状态，（包括READY就绪和RUNNING运行）
3. BLOCKED
	阻塞状态，表示线程阻塞与锁
4. WAITING
	等待状态，当前线程需要等待其他线程通知或中断
5. TIMED_WAITING
	超时等待状态，它可以在指定的时间自行返回
6. TERMINATED

说明：

- 线程创建之后会进入NEW状态，调用start()方法开始运行，线程出去运行状态（细分为READY状态，获得cpu时间片后遍进入RUNNING状态），当线程执行wait()方法之后，会进入WAITING状态，等待其他线程唤醒，回到运行状态（wait(long millis)、Thread.sleep()也是如此，超时过后没有唤醒进入RUNNABLE）。当线程调用同步方法时，**没有获取到锁的情况下**，线程会进入到BLOCKED状态，等待锁的释放。**得到锁之后**，线程会执行run()方法之后会进入到TERMINATED状态。

## 守护线程

在Java中有两类线程，分别是User Thread（用户线程）和Daemon Thread（守护线程）

守护线程，指的是程序运行时在后台**提供的一种通用服务**的线程，它是在操作系统中没有这个概念，而是在JVM中的一个机制。比如垃圾回收线程就是一个很称职的守护者，并且这种线程并不属于程序中不可或缺的部分。因此，当**所有的非守护线程结束**时，**程序也就终止了**，同时会杀死进程中的所有守护线程。反过来说，只要任何非守护线程还在运行，程序就不会终止。

Thread类中提供了一个setDaemon(true)方法来将一个普通的线程（用户线程）设置为守护线程

### 守护线程应用场景

Web服务器中的Servlet，在容器启动时，后台都会初始化一个服务线程，即调度线程，负责处理http请求，然后每个请求过来，调度线程就会从线程池中取出一个工作者线程来处理该请求，从而实现并发控制的目的。也就是说，一个实际应用在Java的线程池中的调度线程。

## 并行与并发的区别 ##

1. 并行：同一个时间点上，依靠CPU多个核心，多个任务同时执行
2. 并发：在一段时间，利用上下文切换也就是CPU时间片调度，看上去多个进程同时都在运行的现象

## 上下文切换 ##
上下文切换：CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。

### 自发性上下文切换 ###
1. Thread.sleep()
2. Object.wait()
3. Thread.yeild()
	线程让步，让当前线程由“运行状态”进入到“就绪状态”，从而让其它具有相同优先级的等待线程获取执行权
4. Thread.join()
	让“主线程”等待“子线程”结束之后才能继续运行，在子线程上使用
5. LockSupport.park()

## 为什么要使用多线程 ##
1. 更多的处理器核心
	一个单线程程序在运行时只能使用一个处理器核心，那么再多的处理器核心加入也无法显著该程序的执行效率。如果该程序使用多线程技术，将计算逻辑分配到多个处理器核心上，就会显著减少程序的处理时间
2. 更快的响应时间
    可以使用多线程技术，将数据一致性不强的操作派发给其他线程处理。响应用户请求的线程能够尽可能快地处理完成，缩短响应时间，提升用户体验。

## 实现多线程有几种方式？

1. 继承Thread类，重写run()方法
2. 实现Runnable接口，实现run()方法
   - 创建Thread对象，用实现Runnable接口的对象作为参数实例化该Thread对象。
3. 实现Callable接口，重写call()方法

## 如何停止一个线程？

1. 调用stop()方法

   调用本地stop0()方法，直接强制停止线程，会释放掉锁占有的锁，假如这些锁恰恰是用来维持对象一致性的。如果此时，写线程写入数据正写到一半，并强行终止，那么对象就会被写坏，同时由于锁已经释放，另外一个等待该锁的读线程就会顺理成章地读到了这个不一致的对象

2. 调用interrupt()方法

   interrupt()其本身并不是一个强制打断线程的方法，其仅仅会修改线程的interrupt标志位，然后让线程自行去读标志位，自行判断是否需要中断

## 线程间的通信方式

1. volatile保证内存可见性，共享内存
2. Object的wait()和notify()方法
3. CountDownLatch，相当于也是维护了一个线程间共享变量state
4. ReentrantLock 结合Condition

## JVM实现线程

1. 使用内核线程实现

2. 使用用户线程实现

   用户线程指完全建立在用户空间的线程库上。这种线程不需要切换内核态，效率非常高且低消耗

3. 用户线程加轻量级进程混合实现


## 实现Runnable接口和Callable接口区别 ##

- Runnable规定的方法是run()， Callable规定的方法是call()

- Runnable接口**不会返回结果或抛出检查异常**，Callable可以拿到一个**Future对象**表示异步计算的结果

- 工具类Executors可以实现Runnable对象转换到Callable对象
	```java
   public static Callable<Object> callable(Runnable task) {
        if (task == null)
            throw new NullPointerException();
        return new RunnableAdapter<Object>(task, null);
   }
  ```

## 执行execute()方法和submit()方法区别 ##

1. execute()方法提交不需要返回值的任务，无法判断任务是否被线程池执行成功

   submit()方法提交需要返回值的任务，通过线程池返回的Future类型的对象判断任务是否成功执行


## 为什么并发执行的速度会比串行慢呢？(百万次) ##
是因为线程有创建和上下文切换的开销
vmstat测量上下文切换的次数

## 减少上下文切换

1. 有无锁并发编程
   如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。
2. CAS算法
   Java的Atomic包使用CAS算法来更新数据，而不需要加锁使用
3. 最少线程
   比如任务很少，但是创建了很多线程来处理，
4. 使用协程
   在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换

## 锁是用来干什么的？ ##
确保多线程同步，从而保证访问资源数据的正确性

## 什么是线程死锁？死锁必要条件？避免死锁方法
### 线程死锁 ###
是指两个或两个以上的线程在执行过程中，因争夺资源而造成的一种互相等待的现象
### 死锁必要条件 ###
1. **互斥**，一段时间内某资源只由一个线程占用
2. **请求和保持**，保持了一个资源，又提出了新的资源请求
3. **不剥夺**，已获得的资源，在未使用完之前，不能被剥夺
4. **环路等待**，若干线程之间形成一种头尾相接的环形等待关系

### 避免死锁方法 ###
破坏四个之中一个条件
1. 无法破坏，锁的作用就是互斥
2. 一次性申请所有资源，或者避免一个线程同时获取多个锁
3. 申请不到资源，主动释放它占有的资源，尝试使用定时锁
4. 按照顺序申请资源，反序释放资源

## sleep()、wait()、park()方法比较 ##
### Thread.sleep() 

​	Thread.sleep(time)方法必须传入指定的时间，线程将进入休眠状态，此时该线程的状态是**TIMED_WAITING**，通过sleep方法进入休眠的线程**不会释放持有的锁**

### Object.wait()

​	如果不传timeout，wait将会进入无限制的休眠当中，直到有人唤醒他。使用wait()让线程进入休眠的话，线程的状态都将是`WAITING`状态，如果传入timeout参数，进入**TIMED_WAITING**状态

**必须获得对象上的锁**后，才可以执行该对象的wait方法。否则程序会在运行时抛出`IllegalMonitorStateException`异常

### LockSupport.park() 

调用park方法进入休眠后，线程状态为**WAITING**，如果调用parkNanos，则进入**TIMED_WAITING**状态

**可以不获得对象的锁**，而是获得许可，unpark()可以在park()之前执行，先发放许可，park()再消费许可，“许可”不能叠加

​	如果在wait()之前执行了notify()会怎样？抛出IllegalMonitorStateException异常；如果在park()之前执行了unpark()会怎样？线程不会被阻塞，直接跳过park()，继续执行后续内容；

### 对比

1. sleep是Thread类的方法，wait是Object类中定义的方法，park是LockSupport定义的方法

2. sleep、park没有释放锁，而wait释放了锁
3. sleep用于暂停执行，wait、park用于线程间的通信
4. wait方法调用后需要别的线程调用同一个对象上的notify()唤醒，而sleep()只能自己醒来，park可以被另一个线程调用unpark唤醒



## notify和notifyAll有什么区别？

如果线程调用了对象的 wait()方法，那么线程便会处于该对象的**等待池**中，等待池中的线程**不会去竞争该对象的锁**

- 有线程调用了对象的 **notifyAll**()方法，会唤醒所有 wait 线程
- 而调用**notify**()方法，只随机唤醒一个 wait 线程

被唤醒的线程，就会与其他线程一起竞争锁

# CAS ---CompareAndSwap 比较并替换 #

 有三个操作数---内存位置V、期望值A、新值B 

如果内存位置的值与期望值匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作

“我认为位置B应该包含值A，如果包含，则将B放到这个位置。否则，不要更改该位置的值，只要告诉我这个位置现在的值即可”

## 怎么使用JDK提供CAS支持？ ##
java中提供了对CAS操作的支持，具体在sun.misc.unsafe类中，优于双亲委派机制，调用getUnsafe无法创建，需要通过反射创建

```java
public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);
public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);
public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);
参数var1：表示要操作的对象
参数var2：表示要操作对象中属性地址的偏移量
参数var4：表示要修改数据的期望值
参数var5：表示需要修改为的新值
```

## CAS实现原理是什么? ##
CAS通过调用Unsafe类的compareAndSwapXxx方法，通过JNI调用C++代码中Unsafe.cpp，有一个cmpxchg函数，会调用汇编指令，以常用的Intel x86平台来说，最终映射到的cpu指令为cmpxchg，若是多核CPU，需要锁总线LOCK_IF_MP，否则cpu执行该原子指令，实现比较并替换

## 现代计算机上百核心，cmpxchg怎么保证多核心下的线程安全？ ##

系统底层进行CAS操作时候，会判断当前系统是否为多核心系统（LOCK_IF_MP），如果是就给总线加锁，只有一个线程会取得总线使用权，后会执行CAS操作


## CAS实现原子操作的三大问题 ##
1. ABA问题
2. 循环时间长开销大
3. 只能保证一个共享变量的原子操作

CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，在CAS方法执行之前，被其它线程修改为了B、然后又修改回了A，那么CAS方法执行检查的时候会发现它的值没有发生变化，但是实际却变化了。这就是CAS的ABA问题。

解决：
给值增加一个修改版本号，每次值变换，都会修改它的版本号，CAS操作时都会去对比次版本号

java中ABA解决方法，AtomicStampedReference主要包含一个对象引用及一个可以自动更新的整数“stamp”的Pair对象来解决ABA问题

```java
public boolean compareAndSet(V   expectedReference,
                             V   newReference,
                             int expectedStamp,
                             int newStamp) {
    Pair<V> current = pair;
    return
        expectedReference == current.reference &&
        expectedStamp == current.stamp &&
        ((newReference == current.reference &&
          newStamp == current.stamp) ||
         casPair(current, Pair.of(newReference, newStamp)));
}
```

先比较期望值和版本号是否与当前一致，然后判断如果新值和新版本当前一致就没有必要创建Pair对象，

# synchronized #
## synchronized关键字 ##
- 解决多个线程访问资源的同步性
- 保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行

1. 在Java早期版本中，synchronized属于重量级锁，效率低下，它是依赖低层操作系统的Mutex Lock实现。挂起和唤醒线程都需要操作系统参与，会导致用户态和内核态之间的转换，时间成本高
2. JDK1.6后，官方从JVM层面对synchronized做了优化。如自旋锁、适应性锁。。

## synchronized关键字三种使用方式 ##
1. 修饰实例方法
	进入同步代码前要获得当前实例对象的锁
2. 修饰静态方法
	类只有一份静态资源，会作用于所有对象实例
3. 修饰代码块
	使用指定的对象进行加锁

## synchronized关键字底层原理 ##
### synchronized同步语句块 ###

使用synchronized用于任意对象来加锁，==JVM将字节码加载到内存以后，会对这两个指令进行解释执行==，在interpreterRuntime.cpp中，一个宏定义的函数IRT_ENTRY_NO_ASYNC方法会解析为指令monitorenter和monitorexit指令

使用javap反汇编命令可以看到，synchronized同步语句块使用的是monitorenter和monitorexit指令	

```
 3: monitorenter
 4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
 7: ldc           #3                  // String synchronized 代码块
 9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
12: aload_1
13: monitorexit
```

1. monitorenter指明同步代码块开始的位置
2. monitorexit指明同步代码块结束的位置
3. 执行monitorenter时，线程试图获取锁，也就是获取monitor（monitor对象存在与每个Java对象的对象头中）的持有权
4. 锁计数器为0则可以获取成功，成功后将锁计数器设为1，执行monitorexit后锁计数器设为0（所以说synchronized是可重入的）

### 为什么有两个monitorexit指令？

如果同步代码块中出现Exception或者Error，则会调用第二个monitorexit指令来保证释放锁

### synchronized修饰的方法 ###

锁对象为当前对象，this，synchronized修饰的方法没有monitorenter和monitorexit指令，而使用ACC_SYNCHRONIZED 标识，JVM通过该标志执行相应的同步调用

```java
public synchronized void method();
    descriptor: ()V
    flags: ACC_PUBLIC, ACC_SYNCHRONIZED
    Code:
		...
}
```

##  JDK1.6 之后锁的底层优化

JDK1.6 对锁的实现引入了大量的优化，如**偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化**等技术来减少锁操作的开销
### ①自旋锁与适应性自旋锁 ###
**一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的**。为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋，默认10次），这项技术就叫做自旋
自适应的自旋锁带来的改进就是：**自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定**

### ②锁消除 ###
它指的就是虚拟机即时编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。

### ③锁粗化 ###
原则上，我们在编写代码的时候，总是推荐将同步块的**作用范围限制得尽量小**，但是如果一系列的连续操作都对**同一个对象反复加锁和解锁**，那么会带来很多不必要的性能消耗。此时虚拟机会**加锁同步的范围扩展（粗化）到整个操作序列的外部**，只需要加一次锁就行了
### ④轻量级锁 ###
轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗
1. 加锁过程：
	- 通过在当前线程的栈帧中建立一个锁记录空间LockRecord，存储MarkWord的拷贝，然后使用CAS操作尝试对象的Mark Word更新为指向的LockRecord，
	- 若成功则该线程获得此对象锁，锁标志变为00
	- 若失败则代表当前线程有竞争，先检查对象的MarkWord是否指向当前线程的栈帧
		- 若是，则说明当前线程已经拥有了这个对象的锁
		- 否则，锁膨胀为重量级锁（锁标志10）
2. 解锁过程：
	- 若对象的MarkWord指向当前线程栈帧，使用CAS操作把对象的MarkWord和线程栈帧中复制的LockRecord替换回来
		- 若替换成功，则完成解锁
		- 否则，说明有其他线程尝试获取锁，在释放锁的同时，唤醒被挂起的线程

轻量级锁能够提升程序同步性能的依据是“**对于绝大部分锁，在整个同步周期内都是不存在竞争的**”，这是一个经验数据。如果没有竞争，**轻量级锁使用 CAS 操作避免了使用互斥操作的开销**。但如果存在锁竞争，**除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢**！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！

### ⑤偏向锁 ###
与轻量锁目的一样，轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量。而偏向锁在无竞争的情况下会把**整个同步都消除掉**。
1. 加锁过程
	- 锁对象第一次被线程获取的时候，虚拟机会把对象头的MarkWord标志位设置为01，偏向模式设置为1
	- 然后使用CAS操作把获取到这个锁的线程的ID记录在对象的MarkWord中
		- 若CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关同步块，都无需同步操作
		- 否则，有线程竞争，偏向模式结束。
		- 根据锁对象是否被锁定来决定是否撤销偏向，撤销后标志位回复到01或者轻量锁00 

小问题：对象进入偏向状态时，MarkWord都用于存储持有锁的线程ID了，原来的哈希码怎么办？ 
Object::hashCode()返回的是对象的一致性哈希码，这个值能保证强制不变，再经过一次计算之后，再次调用得到的哈希码值不会再发生改变

## 锁升级过程

1. 无锁

   首先，无锁状态下，锁标志为`01`，偏向模式为`0`

1. 偏向锁

   当锁对象**第一次**被线程获取的时候会把对象头中的偏向模式改为`1`，同时使用CAS操作把获取到锁线程的ID记录到MarkWord中。如果同一个线程来，不进行同步操作。有线程竞争，偏向模式结束。根据锁对象是否被锁定来决定是否撤销偏向，撤销后标志位回复到01或者轻量锁00

2. 轻量级锁

   通过在当前线程的栈帧中建立一个锁记录空间Lock Record，存储MarkWord的拷贝，然后使用CAS操作尝试对象的Mark Word更新为指向的LockRecord，若失败则代表当前线程有竞争，先检查对象的MarkWord是否指向当前线程的栈帧，如果不是自己则膨胀为重量级锁，锁标志10

# volatile关键字 #

修饰共享变量，被修饰的变量在别修改后会马上同步到主存,这样该线程对这个变量的修改就是对所有其他线程可见的，其他线程能够马上读到这个修改后值。因此不会将该变量上的操作与其它内存操作一起**重排序**，volatile类型的**变量保证了可见性**，**但是不能保证原子性**，在进行自增等非原子性操作的时候依然会出现并发问题。

五层实现：
1. java源码 		volatile int i;
2. ByteCode字节码 	ACC_VOLATILE
3. JVM虚拟机规范 	JVM内存屏障
4. Hotspot中实现 	lock；addl $0 （lock一个空指令，nop也是空指令，但不能被锁）
5. CPU级别		
	> MESI缓存一致性协议
	> 原语支持
	> 总线锁

## DCL单例（Double Check Lock）到底需不需要volatile？ ##
需要，因为对象在初始化的过程中，有一个半初始化的过程，此时如果发生指令重排，另一个线程有可能拿到半初始化的对象

## Java内存模型 JMM ##
目的：
- 定义程序中各种变量的访问规则，让Java的并发内存访问不会产生歧义，但是需要足够宽松，使得虚拟机的实现有足够的自由空间去利用硬件的各种特性。

内存模型：
- 所有的变量都存储在主内存（Main Memory）
- 每个线程有自己的工作内存（Working Memory），**其中保存了被该线程使用的变量的主内存副本**
- **线程对变量的所有操作（读写）都必须在工作内存中进行，不能直接读写主内存中的数据**（volatile也不例外） 

## synchronized关键字和volatile关键字的比较 ##
1. volatile关键字是线程同步的较轻量级实现，volatile性能比synchronized性能好
	volatile关键字只能用于变量，而synchronized关键字可以修饰方法以及代码块
2. 多线程访问volatile变量不会阻塞，而synchronized关键字会阻塞
3. volatile保证数据可见性，不保证数据的原子性。而synchronized两者都保证
4. volatile主要用于解决变量在多个线程之间的可见性，而synchronized解决多个线程之间的访问资源的同步性

它比synchronized的使用和执行成本更低，因为不会引起线程上下文的切换和调度

## 总线嗅探会引发什么问题？

总线风暴，由于volatile的MESI缓存一致性协议，需要不断的从主内存嗅探总线上的数据和cas不断循环，无效的交互会导致总线带宽达到峰值



当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。
当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。
当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。
为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。
JSR-133中，只要volatile变量与普通变量之间的重排序可能会破坏volatile的内存语义，这种重排序就会被编译器重排序规则和处理器内存屏障插入策略禁止。

可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入
原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性

原理：
为了提高处理速度，CPU不会直接和内存进行通信，而是将系统内存的数据读到内部缓存(L1,L2)后再进行操作，但是操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向CPU发送一条Lock前缀的指令，将这个变量所在的缓存行数据写回到系统内存，但此时其他CPU缓存的值还是旧的，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议。
总结：
1.Lock前缀指令会引起处理器缓存回写到内存
2.一个处理器的缓存回写到内存会导致其他处理器的缓存无效。



共享内存：JVM
消息传递：Qt信号和槽(猜测)
【线程之间如何同步】
用于控制不同线程间操作发生的相对顺序

## happens-before

从JDK 5开始，Java使用新的JSR-133内存模型。用happens-before的概念来指定两个操作之间的执行顺序。JMM可以通过happens-before关系向程序
员提供跨线程的内存可见性保证

如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系
只允许把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行，任意的读操作在JSR133中都必须具有原子性。

规则：
1）程序顺序规则：
2）监视器锁规则：
3）volatile变量规则	
4）传递性
5）start()规则
6）join()规则

## as-if-serial

不管怎么重排序，（单线程）程序的执行结果不能被改变

在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。

【重排序】
重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。

【数据依赖性】
如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。
编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序（这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作）

【顺序一致性模型和JMM模型】
1.顺序一致性模型保证单线程内的操作会按程序的顺序执行
2.顺序一致性模型保证所有线程只能看到一致的操作执行顺序
3.JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保证对所有的内存读写操作都具有原子性

【总线机制】
总线的这些工作机制可以把所有处理器对内存的访问以串行化的方式来执行
在任意时间点，最多只能有一个处理器可以访问内存。

【公平锁】
加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得
公平锁在释放锁的最后写volatile变量state，在获取锁时首先读这个volatile变量。根据volatile的happens-before规则，释放锁的线程在写volatile变量之前可见的共享变量，在获取锁的线程读取同一个volatile变量后将立即变得对获取锁的线程可见。

【非公平锁】
加锁前不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待
非公平锁在释放锁的最后写volatile变量state，非公平锁获取时，首先会用CAS更新volatile变量，这个操作同时具有volatile读和volatile写的内存语义

【Java线程之间的通信】
1）A线程写volatile变量，随后B线程读这个volatile变量。
2）A线程写volatile变量，随后B线程用CAS更新这个volatile变量。
3）A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。
4）A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。


【双重检查锁定与延迟初始化】
双重检查锁定是常见的延迟初始化技术，但它是一个错误的用法

【JMM的内存可见性保证】
1.单线程程序。
2.正确同步的多线程程序执行将具有顺序一致性。
3.未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障。

【JSR-133对旧内存模型的修补】
1.增强volatile的内存语义。
2.增强final的内存语义。

【Lock接口】
JDK1.5后出现，与synchronized关键字类似，只是在使用时需要显式地获取和释放锁，却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁的特性

# AQS #


## AQS介绍 ##

AQS全称AbstractQueuedSynchronizer，它是一个用来构建锁和同步器的框架，使用AQS可以简单高效构造出应用广泛的大量同步器，如ReentrantLock，Semaphore，ReentrantReadWriteLock，SynchronousQueue，FutureTask

AQS的主要属性：

```java
private transient volatile Node head; // 队首
private transient volatile Node tail; // 队尾
private volatile int state; // 锁状态，加锁成功则为1，重入+1，解锁-1
private transient Thread exclusiveOwnerThread; // 在其父类中，表示持有锁的那个线程

static final class Node {
	volatile Node prev;
	volatile Node next;
	volatile Thread thread;
｝
```

## AQS加锁过程 ##

![](https://img-blog.csdnimg.cn/20190809165359537.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFfbHl2ZWU=,size_16,color_FFFFFF,t_70)

思想：
1. 如果线程不存在竞争，不会进行入队操作，队列不初始化
2. 如果存在竞争，队列中的第一个线程表示为一个哑结点，
	1. 如果是第二个线程，有资格进行自旋操作
	2. 如果是第三、四、....线程，直接进行park操作

![](https://img-blog.csdnimg.cn/20190809170223640.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFfbHl2ZWU=,size_16,color_FFFFFF,t_70)
在公平锁的实现中，在tryAcquire()方法中，先根据state判断，是否有锁

```java
int c = getState();
if (c == 0) {
    if (!hasQueuedPredecessors() &&
        compareAndSetState(0, acquires)) {
        setExclusiveOwnerThread(current);
        return true;
    }
}
```
然后通过hasQueuedPredecessors()方法判断是否有前置任务（要不要去排队）

```java
public final boolean hasQueuedPredecessors() {
    // The correctness of this depends on head being initialized
    // before tail and on head.next being accurate if the current
    // thread is first in queue.
    Node t = tail; // Read fields in reverse initialization order
    Node h = head;
    Node s;
    return h != t &&
        ((s = h.next) == null || s.thread != Thread.currentThread());
}
```

在线程交替执行的时候，队列不会进行初始化，队列的tail和head都为null，null != null，会返回true
如果线程尝试加锁，发现失败，就把当前线程入队(addWaiter()方法)。此时如果队列为空，会创建一个哑结点，把head和tail都更新为这个哑结点（CAS设置），再把当前线程所在的节点加入到尾部（CAS设置），更新尾节点指针。然后把当前线程进行阻塞（acquireQueued()方法），如果不算哑结点，当前线程的节点在队列中是第一个的话（判断自己的前一个节点是不是头部），则尝试进行自旋一次，然后判断是否应该睡眠(shouldParkAfterFailedAcquire())，通过Node节点中的一些标志位进行判断（拿到上一个节点的waitStatus，也就是拿到了头结点（哑结点）的，），如果第一次进来则返回false，会再进行自旋一次，然后调用park睡眠
假如再来一个线程t3（队列除哑结点，还有元素），它尝试获取锁失败。新一个Node，把当前线程加入进去，直接进行入队操作，然后取得前一个节点，判断不为head节点，不进行自旋，直接进入park流程。
在shouldParkAfterFailedAcquire()中，会拿到前一个节点的waitStatus状态，判断是否为-1，最后退出的时候会使用CAS把waitStatus设置为-1，返回false，然后进入死循环，再次进入shouldParkAfterFailedAcquire()，判断为-1，返回true（下一个节点会把上一个节点的状态值改为休眠）

队列持有锁后执行完成，释放锁的时候还未来得及唤醒其他线程，刚好有线程来请求锁
## 为什么下一个节点会把上一个节点的状态值改为休眠？ ##
1. 当前节点park后无法修改状态
2. 如果在park之前修改状态，此时发生异常，park不会正常执行
3. 解锁时候
自己无法判断自己睡眠？


## AQS原理分析 ##
核心思想：
- 如果被请求的共享资源空闲，则当前请求资源的线程设置为有效的工作线程，并锁定共享资源
- 若共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制使用CLH队列锁实现的，将获取不到锁的线程加入到队列中
同步器包含了两个节点类型的引用，一个指向头节点，而另一个指向尾节点。
	- CLH(Craig Landin and Hagersten)队列是一个虚拟的双向队列（不存在队列实例，仅存在节点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个节点实现锁分配

设置尾节点：基于CAS的方法：compareAndSetTail(Node expect,Node update)
设置首节点：首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点

## AQS对资源的共享方式 ##
1. 独占式 Exclusive
	- 公平锁：按照线程在队列中的排队顺序
	- 非公平锁：无视队列中的顺序，直接抢锁
在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。
2. 共享式 Share
前提：读操作是可以多个线程同时进行的，而写操作要求对资源的独占式访问

## AQS低层使用了模版方法模式 ##
1. 使用者继承AbstractQueuedSynchronizer并重写指定方法（公共资源state的获取与释放）
2. 将AQS组合在自定义同步组件的实现中，并调用其模版方法，这些模版方法会调用使用者重写过的方法
	
		isHeldExclusively()//该线程是否正在独占资源。只有⽤到condition才需要去实现它。
		tryAcquire(int)//独占式。尝试获取资源，成功则返回true，失败则返回false。
		tryRelease(int)//独占式。尝试释放资源，成功则返回true，失败则返回false。
		tryAcquireShared(int)//共享式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可
		资源；正数表示成功，且有剩余资源。
		tryReleaseShared(int
		)//共享方式。尝试释放资源，成功则返回true，失败则返回false。


## AQS组件 ##
### CountDownLatch 倒计时器 ###
- countDownLatch这个类使一个线程等待其他线程各自执行完毕后再执行。
- 是通过一个计数器来实现的，计数器的初始值是线程的数量。
- 每当一个线程执行完毕后，计数器的值就-1，当计数器的值为0时，表示所有线程都执行完毕，然后在闭锁上等待的线程就可以恢复工作了。

使用步骤：
1. 初始化，指定线程个数
2. 每个线程执行后执行latch.countDown();代表一个线程执行完成，待完成的线程数减1。
3. 在需要等待其他线程完成的线程（主线程）中添加latch.await();阻塞该线程，等待其他子线程完成。

### Semaphore 信号量 ###
- 允许多个线程同时访问，可以指定同一时间能访问共享资源的线程数量
- 常用于限制可以访问某些资源的线程数量，例如通过 Semaphore 限流。

使用步骤：
1. 初始化，指定允许的最大线程数
2. 在线程执行前semaphore.acquire();
3. 在线程执行后semaphore.release();

### CyclicBarrier 循环栅栏 ###
字面意思为可循环使用（Cyclic）的屏障（Barrier），多个线程互相等待，直到到达同一个同步点，再继续**一起执行**

- 让**一组线程**达到一个屏障（同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门
- CyclicBarrier和CountDownLatch非常类似，它也可以实现线程间的技术等待，但是它比CountDownLatch更复杂和强大
- CyclicBarrier的计数器提供reset功能，可以多次使用


## ReetrantLock ##
自己实现一把锁：
1. 自旋
	**- 缺点**：耗费CPU资源，没有竞争到锁的线程会一直占用CPU进行CAS操作
	**- 解决思路**：让得不到锁的线程让出CPU
2. yield+自旋
yield()方法让cpu让出资源，如果当只有两个线程进行竞争时，yield是有效的。但是yield()方法只是当前让出cpu，有可能操作系统下次还是运行该线程，线程比较多的时候会失效
3. sleep+自旋
sleep的时间无法确定（应该让别人来唤醒）
4. park+自旋
在LockSupport中封装了UnSafe类中的park方法，该方法**不需要获得锁**就可以让线程WAITING，通过unpark唤醒

默认构造为非公平锁，传入true参数实现公平锁


## ReetrantLock中打断的原理 ##
ReetrantLock提供了一个lockInterruptibly()方法，可以打断等待

首先会尝试获取锁
1. 如果在加锁之前，有发生打断方法，直接响应
2. 若果获取不到锁，
	

lock会调用parkAndCheckInterrupt方法
lockInterruptibly会调用parkAndCheckInterrupt方法，大致和lock方法一样，只不过==会抛出InterruptedException()==，而在lock中仅仅设置==interrupted标志为true==

为了能够让两个lock()都使用这个方法，调用selfInterrupt()会还原用户行为，因为首先Thread.interrupted()会返回boolean值，调用过后会翻转

ReentrantLock的中断和非中断加锁模式的区别在于：线程尝试获取锁操作失败后，在等待过程中，如果该线程被其他线程中断了，它是如何响应中断请求的。lock方法会忽略中断请求，继续获取锁直到成功；而lockInterruptibly则直接抛出中断异常来立即响应中断，由上层调用者处理中断。

## ReentrantLock ##
ReentrantLock的实现依赖于Java同步器框架AbstractQueuedSynchronizer，AQS使用一个整型的volatile变量（命名为state）来维护同步状态 ---- 同步状态表示锁被一个线程重复获取的次数

1. 公平锁
   公平的获取锁，也就是等待时间最长的线程最优先获取锁，也可以说锁获取是顺序的。
   唯一不同的位置为判断条件多了hasQueuedPredecessors()方法，即加入了同步队列中当前节点是否有前驱节点的判断
   公平性锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。
2. 非公平锁
   对于非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁
   非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量

## ReentrantReadWriteLock读写锁 ##
如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16为表示写

1. 写锁
   写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态
2. 读锁
   读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。
3. 锁降级
   锁降级指的是写锁降级成为读锁，当前正占有写锁，再次取到读锁，随后释放写锁。

## synchronized和ReetrantLock的区别与联系 ##
1. 两者都是**可重入锁**
	- 可重入锁：线程获得了某个对象的锁，此时这个对象锁还没有释放，这个线程可以再次获得自己的内部锁。如果不可锁重入的话，会造成死锁。
	- 同一个线程每次获取锁，锁的计数器都自增1，等到锁计数器下降为0才能释放锁
	
2. synchronized依赖于JVM而ReentrantLock依赖于API
	
	- synchronized依赖于JVM，JDK1.6为其进行优化，但都是在虚拟机层面实现的，没有直接暴露
	- ReentrantLock是JDK层面实现的，也就是API层面，需要lock()和unlock()方法来完成
	- 在1.6之前，无论什么情况，synchronized仍会加锁进行上下文切换，而ReentrantLock在线程是交替执行的情况下，Java层面（公平锁通过队列，队列不会进行初始化），进行了解决，不会进行上下文切换
	
3. ReentrantLock比synchronized增加了一些高级功能

   - 等待可中断

    	提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来现实

   - 可实现公平锁
       - ReentrantLock可以指定是公平锁还是非公平锁。
       - 而synchronized只能是非公平锁

   - 可实现选择性通知
       - synchronized与wait()和notify()方法结合可以实现等待/通知机制，是由JVM选择的
       - ReentrantLock类需要借助Condition接口与newCondition()方法，线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。
       - synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题
       - 而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程

【LockSupport】
要阻塞或唤醒一个线程，LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread)方法来唤醒一个被阻塞的线程
JDK1.6增加阻塞对象主要用于问题排查和系统监控。

【Condition】
Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式
获取一个Condition必须通过Lock的newCondition()方法

【线程池核心数配置】
1.CPU密集型任务
	Core＋１
2.I/O密集型（I/0操作速度低，不占用CPU时间）
	２Core＋１
3.等待型任务
	根据平均等待时间，泊松分布



## ThreadLocal ##
通常，我们创建的变量是可以被任何一个线程访问并修改的。ThreadLocal可以让我们在**每一个线程中有自己的专属本地变量**，每个线程操作自己线程的值，避免线程安全问题

使用场景
1. 每个线程需要有自己单独的实例
2. 实例需要在多个方法中共享，但不希望被多线程共享

### 原理 ###

```java
public class Thread implements Runnable {
	//与此线程有关的ThreadLocal值，由ThreadLocal类维护
    ThreadLocal.ThreadLocalMap threadLocals = null;

    //与此线程有关的ThreadLocal值，由InheritableThreadLocals类维护
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
｝
```
因为一个线程内可以存在多个 ThreadLocal 对象，所以其实是 ThreadLocal 内部维护了一个 Map ，这个 Map 不是直接使用的 HashMap ，而是 ThreadLocal 实现的一个叫做 ThreadLocalMap 的静态内部类。

**Thread类**中有一个threadLocals变量和一个inheritableThreadLocals变量，都是ThreadLocalMap类型的变量（为ThreadLocal实现定制化的HashMap），



set方法，会把拿到**当前线程**的**map对象**，然后把**ThreadLocal**对象传入map对象

```java
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}
```

ThreadLocalMap的底层维护一个Entry数组，而作为key的Entry实际是一个弱引用，假设为**强引用**，ThreadLocal对象的引用设为null之后，线程中的Map对象key引用了ThreadLocal对象，所以这个ThreadLocal对象就永远不会被回收。

```java
static class ThreadLocalMap {
    
	private Entry[] table;
    
    static class Entry extends WeakReference<ThreadLocal<?>> {
        /** The value associated with this ThreadLocal. */
        Object value;

        Entry(ThreadLocal<?> k, Object v) {
            super(k);
            value = v;
        }
    }
    
	...
}
```

### ThreadLocal内存泄露问题 ###

ThreadLocalMap中使用的key为ThreadLocal的虚引用，而value是强引用。如果，ThreadLocal没有被外部强引用的情况下，垃圾回收时，key会被清理掉（置为null），而value不会被清理。如果我们不做措施的话，可能产生内存泄露。使用完ThreadLocal方法后，最好手动调用remove()方法，会清理掉key为null的记录

在JDK1.8中，在set方法中for循环遍历整个Entry数组，遇到key=null的就会替换，

### 为什么key要使用弱引用？ ###
因为如果这里使用普通的key-value形式来定义存储结构，实质上就会造成节点的生命周期与线程强绑定，只要线程没有销毁，那么节点在GC分析中一直处于可达状态，没办法被回收，==ThreadLocal是一个强引用和一个弱引用同时指向的==，随着栈帧的销毁，强引用消失，弱引用就会在下一次GC中回收掉

弱引用是Java中四档引用的第三档，比软引用更加弱一些，如果一个对象没有强引用链可达，那么一般活不过下一次GC。当某个ThreadLocal已经没有强引用可达，则随着它被垃圾回收

### ThreaLocalMap中key的HashCode计算 ###
由于ThreadLocalMap使用线性探测法来解决散列冲突，所以实际上Entry[]数组在程序逻辑上是作为一个环形存在的。
ThreaLocalMap的hashcode计算没有采用模长度的方法，没有采用拉链法，采用的是开放地址法，其槽位采用静态的AtomicInteger每次增加1640531527实现，冲突了则加1或者减1继续进行增加1640531527（1640531527 这是一个神奇的数字，能够让hash槽位分布相当均匀）

ThreadLocal往往存放的数据量不会特别大，而且key是弱引用，会被垃圾回收，采用开放定址法会更省空间，而且查询效率更高。

### 应用

Spring中使用ThreadLocal保证单例对象对各个线程之间的安全

Spring中使用ThreadLocal保证事务，@Transactional

一个方法，调用了另外的多个方法（事务之间的传播），他们拿到的数据库连接必须是同一个

这些方法同属一个线程，使用ThreadLocal把connection放入线程


##  Atomic原子类  ##
原子类就是具有原子/原子操作特征的类，一个操作是不可中断的，即使多个线程一起执行，不会互相干扰

## 原子类是哪四类？ ##
1. 基本类型：
	- AtomicInteger
	- AtomicLong
	- AtomicBoolean
2. 数组类型
	- AtomicIntegerArray
	- AtomicLongArray
	- AtomicReferenceArray
3. 引用类型
	- AtomicReference
	- AtomicStampedReference 原子更新引用类型里的字段
	- AtomicMarkableReference 原子更新带有标记位的引用类型
4. 对象的属性修改类型
	- AtomicIntegerFieldUpdater
	- AtomicLongFieldUpdater
	- AtomicStampedUpdater：原子更新带有版本号的引用类型，可以解决使用CAS出现的ABA问题

## AtomicInteger的使用 ##
```java
public final int get() //获取当前的值
public final int getAndSet(int newValue)//获取当前的值，并设置新的值
public final int getAndIncrement()//获取当前的值，并⾃增
public final int getAndDecrement() //获取当前的值，并⾃减
public final int getAndAdd(int delta) //获取当前的值，并加上预期的值
boolean compareAndSet(int expect, int update) //如果输⼊的数值等于预期值，则以原⼦
⽅式将该值设置为输⼊值（update）
public final void lazySet(int newValue)//最终设置为newValue,使⽤ lazySet 设置之
后可能导致其他线程在之后的⼀⼩段时间内还是可以读到旧的值。
```

## AtomicInteger类的原理 ##
```java
// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“⽐较并替
换”的作用）
 private static final Unsafe unsafe = Unsafe.getUnsafe();
 private static final long valueOffset;
 static {
	 try {
	 	valueOffset = unsafe.objectFieldOffset
						(AtomicInteger.class.getDeclaredField("value"));
	 } catch (Exception ex) { throw new Error(ex); }
 }
 private volatile int value;
```

AtomicInteger类主要利用CAS+volatile和native方法保证原子操作，避免synchronized高开销，提升执行效率
- CAS拿期望的值和原本的值做比较，如果相同则更新为新的值
- UnSafe类的objectFieldOffset()方法可以拿到“原来的值”的内存地址

## LongAdder

JDK1.8中引入，AtomicLong 和LongAdder在低并发下差不多，而在高并发下LongAdder有更好的性能，但同时有更好的消耗

**LongAdder**的基本思路就是**分散热点**，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。

在其父类Striped64中，维护了一个base变量，一个Ceil数组（使用@Contended消除伪共享）

`base`变量：非竞争条件下，直接累加到该变量上
`Cell[]`数组：竞争条件下，累加个各个线程自己的槽`Cell[i]`中

```java
abstract class Striped64 extends Number {

	transient volatile Cell[] cells;
    transient volatile long base;

    @sun.misc.Contended static final class Cell {
        volatile long value;
        ...
    }
}
```

## new一个Thread的底层 ##

实质是操作系统内核调用clone()，得到一个系统级别的线程

## 如何模拟高并发？ ##
1. 定义多个线程
2. 使用CountDownLatch控制线程实例化，启动之后计数器-1
3. 在线程内部，执行业务前调用await()方法
4. 当CountDownLatch计数器为0时，所有的线程同时开始执行

注：依赖于CPU的核心数量，真正同时执行的时候只能一个CPU一个线程